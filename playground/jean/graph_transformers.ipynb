{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3a656a-cb4e-492f-8b0f-aa8e445b3968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from seiz_eeg.dataset import EEGDataset\n",
    "from torch.utils.data import Dataset\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import TransformerConv, global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be21785-8d4a-4ab0-b504-8bf340fdd5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    # Python random module\n",
    "    random.seed(seed)\n",
    "    # Numpy random module\n",
    "    np.random.seed(seed)\n",
    "    # Torch random seeds\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "\n",
    "    # Set PYTHONHASHSEED environment variable for hash-based operations\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    \n",
    "    # Ensure deterministic behavior in cudnn (may slow down your training)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e16bfd-dd67-4cb6-b38e-4a15180b8b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd840db-f615-4b2f-8a5c-cbe08c393104",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7d423b-949c-4196-b227-9406ebf19bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/ogut/data\"\n",
    "DATA_ROOT = Path(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c2fe6e-c160-4e5a-b7e2-f438fa800f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clips_tr = pd.read_parquet(DATA_ROOT / \"train/segments.parquet\")\n",
    "clips_te = pd.read_parquet(DATA_ROOT / \"test/segments.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146726ae-9916-4495-a297-0af719fbc78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DISTANCE = 1\n",
    "adjacency_matrix = pd.read_csv('distances_3d.csv').pivot(index='from', columns='to', values='distance').to_numpy()\n",
    "adjacency_matrix = (adjacency_matrix <= MAX_DISTANCE).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a073c90-f776-48b2-8a60-fff91043faf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEEGDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        clips_df: pd.DataFrame,\n",
    "        signals_root: Path,\n",
    "        adjacency_matrix: np.ndarray,\n",
    "        prefetch: bool = True\n",
    "    ):\n",
    "        self.dataset = EEGDataset(\n",
    "            clips_df=clips_df,\n",
    "            signals_root=signals_root,\n",
    "            prefetch=prefetch,\n",
    "        )\n",
    "        self.edge_index = torch.tensor(np.array(np.nonzero(adjacency_matrix)), dtype=torch.long)\n",
    "        self.edge_attr = torch.tensor(adjacency_matrix[np.nonzero(adjacency_matrix)], dtype=torch.float32)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Data:\n",
    "        x, y = self.dataset[idx]\n",
    "        return Data(\n",
    "            x=torch.tensor(x, dtype=torch.float32).transpose(0, 1),\n",
    "            edge_index=self.edge_index,\n",
    "            edge_attr=self.edge_attr,\n",
    "            y=torch.tensor(y, dtype=torch.long),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68449abf-9ae9-46c5-b2c0-b4b49237ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tr = GraphEEGDataset(\n",
    "    clips_tr,\n",
    "    signals_root=DATA_ROOT / \"train\",\n",
    "    adjacency_matrix=adjacency_matrix,\n",
    "    prefetch=True,\n",
    ")\n",
    "\n",
    "dataset_tr, dataset_val = torch.utils.data.random_split(dataset_tr, [0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f254045-64cf-42e7-8cce-c83cc8eaddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_tr  = DataLoader(dataset_tr, batch_size=64, shuffle=True, num_workers=4)\n",
    "loader_val = DataLoader(dataset_val, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae1eb5a-3143-4424-9a0b-0daaacdaeadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowBatcher(nn.Module):\n",
    "    def __init__(self, window_size: int = 50, step_size: int = 25):\n",
    "        super().__init__()\n",
    "        self.window_size = window_size\n",
    "        self.step_size = step_size\n",
    "\n",
    "    def forward(self, batch: Batch) -> Batch:\n",
    "        x          = batch.x\n",
    "        edge_index = batch.edge_index\n",
    "        edge_attr  = batch.edge_attr\n",
    "        y          = batch.y\n",
    "        ptr        = batch.ptr\n",
    "        \n",
    "        batch_size      = ptr.numel() - 1\n",
    "        nodes_per_graph = x.size(0) // batch_size\n",
    "        features_dim    = x.size(1)\n",
    "        edges_per_graph = edge_index.size(1) // batch_size\n",
    "\n",
    "        edge_index_per_graph = []\n",
    "        edge_attr_per_graph = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            node_offset = ptr[i].item()\n",
    "            node_end = ptr[i+1].item()\n",
    "            mask = (edge_index[0] >= node_offset) & (edge_index[0] < node_end)\n",
    "            edge_index_per_graph.append(edge_index[:, mask] - node_offset) # local indexing\n",
    "            edge_attr_per_graph.append(edge_attr[mask]) \n",
    "\n",
    "        x = x.view(batch_size, nodes_per_graph, features_dim)\n",
    "        x = x.unfold(dimension=2, size=self.window_size, step=self.step_size)  # (B, N, W, F)\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()  # (B, W, N, F)\n",
    "        x = x.view(-1, nodes_per_graph, self.window_size)  # (B * W, N, F)\n",
    "\n",
    "        windows_per_graph = x.size(0) // batch_size\n",
    "        return Batch.from_data_list([\n",
    "            Data(\n",
    "                x=x[i],\n",
    "                edge_index=edge_index_per_graph[i // windows_per_graph],\n",
    "                edge_attr=edge_attr_per_graph[i // windows_per_graph],\n",
    "                y=y[i // windows_per_graph]\n",
    "            )\n",
    "            for i in range(x.size(0))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680c755-a109-4040-ac42-aff8fba66095",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphTransformer(nn.Module):\n",
    "    def __init__(self, in_channels: int, hidden_channels: int, out_channels: int, heads: int = 4):\n",
    "        super().__init__()\n",
    "        self.layer_1 = TransformerConv(in_channels, hidden_channels, heads=heads)\n",
    "        self.activation_1 = nn.GELU()\n",
    "        self.layer_2 = TransformerConv(hidden_channels * heads, hidden_channels, heads=1)\n",
    "        self.activation_2 = nn.GELU()\n",
    "        self.linear = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data: Batch) -> torch.tensor:\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.layer_1(x, edge_index)\n",
    "        x = self.activation_1(x)\n",
    "        x = self.layer_2(x, edge_index)\n",
    "        x = self.activation_2(x)        \n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4907698c-ac48-4ca7-83a4-048cb654ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int = 512,\n",
    "        nhead: int = 8,\n",
    "        dim_feedforward: int = 2048,\n",
    "        num_layers: int = 4,\n",
    "        max_seq_len: int = 512\n",
    "    ):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        position = torch.arange(0, max_seq_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))  # (1, max_seq_len, d_model)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=nhead, \n",
    "            dim_feedforward=dim_feedforward, \n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=encoder_layer,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        x = self.encoder(x)\n",
    "        x = x.mean(dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f5a37-69f3-4f90-997c-1e76ec0386a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeizureClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        window_size: int = 50,\n",
    "        step_size: int = 25,\n",
    "        graph_hidden_channels: int = 64,\n",
    "        graph_heads: int = 4,\n",
    "        d_model: int = 512,\n",
    "        nhead: int = 8,\n",
    "        dim_feedforward: int = 2048,\n",
    "        num_layers: int = 4,\n",
    "        max_seq_len: int = 512,\n",
    "    ):\n",
    "        super().__init__()  \n",
    "        self.d_model = d_model\n",
    "        self.sliding_window_batcher = SlidingWindowBatcher(\n",
    "            window_size=window_size, \n",
    "            step_size=step_size\n",
    "        )\n",
    "        \n",
    "        self.graph_transformer = GraphTransformer(\n",
    "            in_channels=window_size,\n",
    "            hidden_channels=graph_hidden_channels, \n",
    "            out_channels=d_model,\n",
    "            heads=graph_heads\n",
    "        )\n",
    "        self.encoder = Encoder(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            num_layers=num_layers,\n",
    "            max_seq_len=max_seq_len\n",
    "        )\n",
    "        self.classifier = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, batch: Batch) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        x: (B * N, F)\n",
    "        edge_index: (2, B * N * (N-1))\n",
    "        edge_attr: (B * N * (N-1))\n",
    "        y: (B)\n",
    "        \"\"\"\n",
    "        batch_size = batch.y.size(0)\n",
    "        \n",
    "        \"\"\"\n",
    "        x: (B * W * N, L) \n",
    "        edge_index: (2, B * W * N * (N-1))\n",
    "        edge_attr: (B * W * N * (N-1))\n",
    "        y: (B * W)\n",
    "        \"\"\"\n",
    "        batch = self.sliding_window_batcher(batch)\n",
    "        windows_per_graph = batch.y.size(0) // batch_size\n",
    "\n",
    "        graph_embeddings = self.graph_transformer(batch) # (B * W, D)\n",
    "        graph_embeddings = graph_embeddings.reshape(batch_size, windows_per_graph, self.d_model) # (B, W, D)\n",
    "\n",
    "        time_series_embeddings = self.encoder(graph_embeddings) # (B, D)\n",
    "        \n",
    "        logits = self.classifier(time_series_embeddings) # (B, 1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a45e43c-f6f8-4066-8317-a3517c9fcd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, epoch, loader_tr, optimizer, criterion, metrics):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    accuracy = 0\n",
    "    f1 = 0\n",
    "    for batch in tqdm(loader_tr, desc=f\"Epoch {epoch +1}\"):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions = torch.round(torch.sigmoid(outputs))\n",
    "            accuracy += accuracy_score(predictions.cpu(), batch.y.cpu())\n",
    "            f1 += f1_score(predictions.cpu(), batch.y.cpu())\n",
    "\n",
    "        loss = criterion(outputs.view(-1), batch.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(loader_tr)\n",
    "    accuracy /= len(loader_tr)\n",
    "    f1 /= len(loader_tr)\n",
    "\n",
    "    metrics[\"train\"][\"loss\"].append(train_loss)\n",
    "    metrics[\"train\"][\"accuracy\"].append(accuracy)\n",
    "    metrics[\"train\"][\"f1\"].append(f1)\n",
    "    \n",
    "    print('Train Loss: {:.4f}, '.format(train_loss),'Train Accuracy: {:.4f}, '.format(accuracy),'Train F1-Score: {:.4f}, '.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a3367b-418d-4230-97be-03963ca834a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, loader_val, criterion, metrics):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    accuracy = 0\n",
    "    f1 = 0\n",
    "    for batch in loader_val:\n",
    "        with torch.no_grad():\n",
    "            batch = batch.to(device)\n",
    "            outputs = model(batch)\n",
    "\n",
    "            loss = criterion(outputs.view(-1), batch.y.float())\n",
    "            predictions = torch.round(torch.sigmoid(outputs))\n",
    "        \n",
    "            eval_loss += loss.item()\n",
    "            accuracy += accuracy_score(predictions.cpu(), batch.y.cpu())\n",
    "            f1 += f1_score(predictions.cpu(), batch.y.cpu())\n",
    "            \n",
    "    eval_loss /= len(loader_val)\n",
    "    accuracy /= len(loader_val)\n",
    "    f1 /= len(loader_val)\n",
    "\n",
    "    metrics[\"eval\"][\"loss\"].append(eval_loss)\n",
    "    metrics[\"eval\"][\"acc\"].append(accuracy)\n",
    "    metrics[\"eval\"][\"f1\"].append(f1)\n",
    "\n",
    "    print('Val Loss: {:.4f}, '.format(eval_loss),'Val Accuracy: {:.4f}, '.format(accuracy),'Val F1-Score: {:.4f}, '.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d10a9d-e397-41d9-bb77-2fe599820454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, loader_tr, loader_val, optimizer, criterion):\n",
    "    metrics = dict()\n",
    "    metrics[\"train\"] = defaultdict(list)\n",
    "    metrics[\"eval\"] = defaultdict(list)\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        train_epoch(model, epoch, loader_tr, optimizer, criterion, metrics)\n",
    "        eval_epoch(model, loader_val, criterion, metrics)\n",
    "    \n",
    "        current_f1 = metrics[\"eval\"][\"f1\"][-1]\n",
    "        if current_f1 > best_f1:\n",
    "            best_f1 = current_f1\n",
    "            torch.save(model.state_dict(), f\"./best_model.pt\")\n",
    "            print(f\"âœ… Best model saved with F1: {best_f1:.4f} as best_model.pt\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d77313-e897-48c2-a772-020053a1e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SeizureClassifier(\n",
    "    window_size=125,\n",
    "    step_size=62,\n",
    "    graph_hidden_channels=128,\n",
    "    graph_heads=4,\n",
    "    d_model=512,\n",
    "    nhead=8,\n",
    "    dim_feedforward=2048,\n",
    "    num_layers=8,\n",
    "    max_seq_len=256\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c7727d-b66e-410a-860f-b8edaab3e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=0)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2e28a7-9687-4e5d-9949-5f5ccd0e8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = train(model, 10, loader_tr, loader_val, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134fbf94-2f65-4f61-8c77-246344f83f30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nml",
   "language": "python",
   "name": "nml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
