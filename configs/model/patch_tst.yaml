module:
  _target_: helpers.models.patch_tst.PatchTSTWrapper
  num_input_channels: 19
  num_targets: 1
  context_length: 354
  patch_length: 12
  patch_stride: 12
  num_hidden_layers: 1
  d_model: 64
  num_attention_heads: 4
  share_embedding: True
  share_projection: True
  channel_attention: True
  norm_type: layernorm
  use_cls_token: True
  attention_dropout: 0.1
  positional_dropout: 0.1
  patch_dropout: 0.1
signal_transform: fft_filtering