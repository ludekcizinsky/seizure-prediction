module:
  _target_: helpers.models.patch_tst.PatchTSTWrapper
  num_input_channels: 19
  num_targets: 1
  context_length: 354
  patch_length: 12
  patch_stride: 12
  num_hidden_layers: 3
  d_model: 128
  num_attention_heads: 4
  share_embedding: True
  share_projection: False
  channel_attention: False
  norm_type: layernorm
  use_cls_token: True
signal_transform: fft_filtering