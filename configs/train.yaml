# ==== Our prediction pipeline
# Raw signal (3000, 19) -> Signal Transform -> Temporal Module -> Graph Module -> Classifier
defaults:
  - signal_transform: fft
  - temporal_module: disabled
  - graph_builder: distance # must be disabled when graph_module is disabled
  - graph_module: gcn 
  - _self_

# ==== Training details
# General info
username: 'cizinsky' # your izar username (relevant only on izar)
seed: 42
debug: False # to avoid logging into wandb, instead we log locally using Tensorboard
output_dir: /scratch/izar/${username}/netml/outputs # will be created if it doesn't exist
repo_root: /home/${username}/netml-project/ # path to the repo on your machine
launch_cmd: null # will be set in train.py during runtime

# W&B 
logger:
  # do NOT change project or entity, this ensures that we log experiments to the same project and entity
  # the project is accessible to public,therefore everyone can log there
  # w&b automatically figures your username from the environment variable WANDB_API_KEY
  project: seizure-prediction 
  entity: ludekcizinsky 
  tags: [part1] # practical when trying to filter experiments

# Data 
data:
  subset: -1 # -1 = disable, else int, we have around 11k samples
  trn_frac: 0.9 # = 11693 train samples, and 1300 val samples
  batch_size: 512
  num_workers: 20
  root: /scratch/izar/${username}/netml/data # path to the data
  prefetch: True # should be always true, unless you are on your laptop
  normalize: False
  use_weighted_sampler: False # if True, we use a weighted sampler to balance the classes during training


# Optimisation
optim:
  lr: 5e-4
  weight_decay: 0.0
  warmup_epochs: 50

  # Scheduler - reduce on plateau
  plateau_patience: 10 # how many val/f1 to wait before reducing
  plateau_factor: 0.5 # reduce by this factor
  min_lr: 1e-6  # minimum learning rate

  # Gradient clipping
  max_grad_norm: 1.0 # gradient clipping
  grad_norm_type: 2.0 # norm type for gradient clipping

# PL trainer 
trainer:
  max_epochs: 1000
  accelerator: gpu
  devices: 1
  check_val_every_n_epoch: 25
  precision: 32


# Just to let Hydra know where to save the config file
hydra:
  run:
    dir: ${output_dir}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  job:
    chdir: False