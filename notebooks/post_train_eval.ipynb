{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.expanduser(\"~/netml-project\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "from helpers.pl_module import SeizurePredictor\n",
    "from helpers.dataset import get_dataloaders, get_datasets\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from torchmetrics.functional.classification import binary_f1_score, binary_accuracy\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "First things first, make sure that below you have your username if on izar, else, make sure that the CKPT_DIR is set to the correct path - where you want to download the checkpoint. In additin, also make sure that the SUBMISSION_DIR is set to the correct path - where you want to save the submission file. Ideally, you should save it in the root of the netml-project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"cizinsky\"\n",
    "CKPT_DIR = f\"/scratch/izar/{username}/netml/outputs/tmp\"\n",
    "SUBMISSION_DIR = f\"/home/{username}/netml-project/submissions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $CKPT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the best model from wandb and load it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, filter the runs by tag for instance ang get an overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trb0772b | rural-wildflower-56 | tags: ['dev'] | val/f1: 0.6857143640518188\n",
      "ehlsxvfy | fragrant-elevator-57 | tags: ['dev'] | val/f1: 0.6857143640518188\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "\n",
    "runs = api.runs(\"ludekcizinsky/seizure-prediction\")\n",
    "\n",
    "tagged_runs = [run for run in runs if \"dev\" in run.tags]\n",
    "\n",
    "for run in tagged_runs:\n",
    "    print(f\"{run.id} | {run.name} | tags: {run.tags} | val/f1: {run.summary.get('val/f1')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you can choose specific run (based on the run id - most left column) and download the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded checkpoint to /scratch/izar/cizinsky/netml/outputs/tmp.\n"
     ]
    }
   ],
   "source": [
    "run_id = \"trb0772b\"\n",
    "run = next((run for run in runs if run.id == \"trb0772b\"), None)\n",
    "assert run is not None, \"Run not found!\"\n",
    "\n",
    "artifact_path = f\"ludekcizinsky/seizure-prediction/model-{run_id}:best\"\n",
    "artifact = api.artifact(artifact_path, type=\"model\")\n",
    "artifact.download(CKPT_DIR)\n",
    "print(f\"Downloaded checkpoint to {CKPT_DIR}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, load the model from the checkpoint and set it to evaluation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_module = SeizurePredictor.load_from_checkpoint(f\"{CKPT_DIR}/model.ckpt\")\n",
    "pl_module.eval().freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Finally, inference time! Let's start with loading the val data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FYI: using the following signal transform: normalize -> fft_filtering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cizinsky/venvs/netml/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 /home/cizinsky/venvs/netml/lib/python3.10/site-pack ...\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "_, val_dataloader = get_dataloaders(pl_module.hparams)\n",
    "trainer = Trainer(accelerator=\"gpu\", devices=1, logger=False, callbacks=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can predict the outputs, and map them into single tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cizinsky/venvs/netml/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 /home/cizinsky/venvs/netml/lib/python3.10/site-pack ...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8737200731b64721ab700b515fb8f425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict\n",
    "outputs = trainer.predict(pl_module, val_dataloader)\n",
    "\n",
    "# Map into single tensor\n",
    "preds = torch.cat([output[\"preds_batch\"] for output in outputs])\n",
    "y = torch.cat([output[\"y_batch\"] for output in outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can compute the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8900, F1: 0.6857\n"
     ]
    }
   ],
   "source": [
    "acc = binary_accuracy(preds, y)\n",
    "f1 = binary_f1_score(preds, y)\n",
    "print(f\"Accuracy: {acc:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, now that we have loaded the model, evaluated it on the val set, we can test it on the test set. Let's start loading the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FYI: using the following signal transform: normalize -> fft_filtering\n"
     ]
    }
   ],
   "source": [
    "test_dataset = get_datasets(pl_module.hparams, split=\"test\")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=pl_module.hparams.data.batch_size,\n",
    "    num_workers=pl_module.hparams.data.num_workers,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we run the inference and collect the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cizinsky/venvs/netml/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3 /home/cizinsky/venvs/netml/lib/python3.10/site-pack ...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c061faa8cf4eefb632fe2e8e031141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs = trainer.predict(pl_module, test_dataloader)\n",
    "preds = torch.cat([output[\"preds_batch\"] for output in outputs]).cpu().numpy()\n",
    "sample_ids = []\n",
    "for output in outputs:\n",
    "    sample_ids.extend(output[\"y_batch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create the submission file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pqejgcvm_s001_t000_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pqejgcvm_s001_t000_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pqejgcvm_s001_t000_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pqejgcvm_s001_t000_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pqejgcvm_s001_t000_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  label\n",
       "0  pqejgcvm_s001_t000_0      0\n",
       "1  pqejgcvm_s001_t000_1      0\n",
       "2  pqejgcvm_s001_t000_2      1\n",
       "3  pqejgcvm_s001_t000_3      0\n",
       "4  pqejgcvm_s001_t000_4      0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.DataFrame({\"id\": sample_ids, \"label\": preds})\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle submission file generated: /home/cizinsky/netml-project/submissions/run_trb0772b.csv\n"
     ]
    }
   ],
   "source": [
    "subm_path = os.path.join(SUBMISSION_DIR, f\"run_{run_id}.csv\")\n",
    "submission_df.to_csv(subm_path, index=False)\n",
    "print(f\"Kaggle submission file generated: {subm_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
