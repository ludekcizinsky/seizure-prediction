{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86083770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0509469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import ast\n",
    "\n",
    "def safe_parse(val):\n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(val)\n",
    "            if isinstance(parsed, dict):\n",
    "                return parsed\n",
    "        except Exception:\n",
    "            pass\n",
    "    return val\n",
    "\n",
    "def flatten_config(config, parent_key=\"\", sep=\".\"):\n",
    "    items = {}\n",
    "    for k, v in config.items():\n",
    "        parsed = safe_parse(v)\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(parsed, dict):\n",
    "            items.update(flatten_config(parsed, new_key, sep=sep))\n",
    "        else:\n",
    "            items[new_key] = parsed\n",
    "    return items\n",
    "\n",
    "def parse_param_count(log_str):\n",
    "    match = re.search(r\"([\\d\\.]+)\\s*([KMB])\\s+Trainable params\", log_str)\n",
    "    if not match:\n",
    "        return None  # Or raise an error / fallback value\n",
    "\n",
    "    value, unit = match.groups()\n",
    "    value = float(value)\n",
    "\n",
    "    multiplier = {\n",
    "        \"K\": 1e3,\n",
    "        \"M\": 1e6,\n",
    "        \"B\": 1e9,\n",
    "    }.get(unit.upper(), 1)\n",
    "\n",
    "    return int(value * multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "213545b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your W&B project\n",
    "ENTITY = \"ludekcizinsky\"  # e.g., \"myusername\" or team name\n",
    "PROJECT = \"seizure-prediction\"\n",
    "\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b3ffeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = api.runs(f\"{ENTITY}/{PROJECT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0d8d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ced14f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = run.history(samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97c44659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optim/grad_norm_postclip</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>_runtime</th>\n",
       "      <th>optim/lr</th>\n",
       "      <th>val/loss</th>\n",
       "      <th>val/f1_class_0</th>\n",
       "      <th>trainer/global_step</th>\n",
       "      <th>val/f1_class_1</th>\n",
       "      <th>optim/grad_norm_preclip</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/f1_macro</th>\n",
       "      <th>_step</th>\n",
       "      <th>val/acc</th>\n",
       "      <th>val/f1_macro</th>\n",
       "      <th>train/acc</th>\n",
       "      <th>train/f1_class_1</th>\n",
       "      <th>train/f1_class_0</th>\n",
       "      <th>_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.331943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.423628</td>\n",
       "      <td>0.902896</td>\n",
       "      <td>574</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>0.824615</td>\n",
       "      <td>0.499067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748095e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>171.148362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.484767</td>\n",
       "      <td>0.860174</td>\n",
       "      <td>1149</td>\n",
       "      <td>0.448669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.654421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748095e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251.848982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.475894</td>\n",
       "      <td>0.863351</td>\n",
       "      <td>1724</td>\n",
       "      <td>0.465028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76</td>\n",
       "      <td>0.782308</td>\n",
       "      <td>0.664190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748095e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>333.917840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.408851</td>\n",
       "      <td>0.910944</td>\n",
       "      <td>2299</td>\n",
       "      <td>0.413994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "      <td>0.845385</td>\n",
       "      <td>0.662469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748095e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413.993400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.393506</td>\n",
       "      <td>0.915863</td>\n",
       "      <td>2874</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>0.852308</td>\n",
       "      <td>0.656045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748095e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>495.125075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.394339</td>\n",
       "      <td>0.913526</td>\n",
       "      <td>3449</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.674154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748095e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>575.901231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.437327</td>\n",
       "      <td>0.906987</td>\n",
       "      <td>4024</td>\n",
       "      <td>0.187266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180</td>\n",
       "      <td>0.833077</td>\n",
       "      <td>0.547126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748096e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>655.830817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.388706</td>\n",
       "      <td>0.916630</td>\n",
       "      <td>4599</td>\n",
       "      <td>0.381877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>206</td>\n",
       "      <td>0.853077</td>\n",
       "      <td>0.649254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748096e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>736.662869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.384982</td>\n",
       "      <td>0.916044</td>\n",
       "      <td>5174</td>\n",
       "      <td>0.412308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232</td>\n",
       "      <td>0.853077</td>\n",
       "      <td>0.664176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748096e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>816.903189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.392373</td>\n",
       "      <td>0.914031</td>\n",
       "      <td>5749</td>\n",
       "      <td>0.456338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>258</td>\n",
       "      <td>0.851538</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748096e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>897.532951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.418869</td>\n",
       "      <td>0.899403</td>\n",
       "      <td>6324</td>\n",
       "      <td>0.482269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>284</td>\n",
       "      <td>0.831538</td>\n",
       "      <td>0.690836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748096e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>978.534050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.381025</td>\n",
       "      <td>0.916993</td>\n",
       "      <td>6899</td>\n",
       "      <td>0.361204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310</td>\n",
       "      <td>0.853077</td>\n",
       "      <td>0.639098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748096e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1058.626954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.381694</td>\n",
       "      <td>0.917247</td>\n",
       "      <td>7474</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.646124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748096e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1139.106589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.368728</td>\n",
       "      <td>0.919469</td>\n",
       "      <td>8049</td>\n",
       "      <td>0.464706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>362</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.692087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748096e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1219.644784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.366494</td>\n",
       "      <td>0.916593</td>\n",
       "      <td>8624</td>\n",
       "      <td>0.409938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>388</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.663266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748096e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1300.358550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.367841</td>\n",
       "      <td>0.916890</td>\n",
       "      <td>9199</td>\n",
       "      <td>0.486188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>414</td>\n",
       "      <td>0.856923</td>\n",
       "      <td>0.701539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748096e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1380.871074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.374723</td>\n",
       "      <td>0.918261</td>\n",
       "      <td>9774</td>\n",
       "      <td>0.373333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>440</td>\n",
       "      <td>0.855385</td>\n",
       "      <td>0.645797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748096e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1461.261566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.367390</td>\n",
       "      <td>0.919037</td>\n",
       "      <td>10349</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>466</td>\n",
       "      <td>0.857692</td>\n",
       "      <td>0.665868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748096e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1542.415384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.367741</td>\n",
       "      <td>0.915556</td>\n",
       "      <td>10924</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>492</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.686349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748096e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1622.752337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.355994</td>\n",
       "      <td>0.920691</td>\n",
       "      <td>11499</td>\n",
       "      <td>0.478134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>518</td>\n",
       "      <td>0.862308</td>\n",
       "      <td>0.699413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748097e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1703.204886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.364386</td>\n",
       "      <td>0.913960</td>\n",
       "      <td>12074</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>544</td>\n",
       "      <td>0.849231</td>\n",
       "      <td>0.652632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748097e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1783.678488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.365489</td>\n",
       "      <td>0.918090</td>\n",
       "      <td>12649</td>\n",
       "      <td>0.410095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>570</td>\n",
       "      <td>0.856154</td>\n",
       "      <td>0.664092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748097e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1864.436327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.364093</td>\n",
       "      <td>0.915069</td>\n",
       "      <td>13224</td>\n",
       "      <td>0.546341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>596</td>\n",
       "      <td>0.856923</td>\n",
       "      <td>0.730705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748097e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1945.375028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.350609</td>\n",
       "      <td>0.924113</td>\n",
       "      <td>13799</td>\n",
       "      <td>0.546917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>622</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.735515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748097e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2026.038777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.373286</td>\n",
       "      <td>0.918190</td>\n",
       "      <td>14374</td>\n",
       "      <td>0.377483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>648</td>\n",
       "      <td>0.855385</td>\n",
       "      <td>0.647837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748097e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2106.984787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.349313</td>\n",
       "      <td>0.921700</td>\n",
       "      <td>14949</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>674</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.721124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748097e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2187.649082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.370402</td>\n",
       "      <td>0.901212</td>\n",
       "      <td>15524</td>\n",
       "      <td>0.533040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>700</td>\n",
       "      <td>0.836923</td>\n",
       "      <td>0.717126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748097e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2268.608411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.357784</td>\n",
       "      <td>0.919085</td>\n",
       "      <td>16099</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>726</td>\n",
       "      <td>0.858462</td>\n",
       "      <td>0.677334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748097e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2349.287016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.341467</td>\n",
       "      <td>0.921826</td>\n",
       "      <td>16674</td>\n",
       "      <td>0.552972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>752</td>\n",
       "      <td>0.866923</td>\n",
       "      <td>0.737399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748097e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2430.125920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.377868</td>\n",
       "      <td>0.922203</td>\n",
       "      <td>17249</td>\n",
       "      <td>0.429487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>778</td>\n",
       "      <td>0.863077</td>\n",
       "      <td>0.675845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748097e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2510.835882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.380593</td>\n",
       "      <td>0.924570</td>\n",
       "      <td>17824</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>804</td>\n",
       "      <td>0.868462</td>\n",
       "      <td>0.705528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748097e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2591.432219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.347539</td>\n",
       "      <td>0.922321</td>\n",
       "      <td>18399</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>830</td>\n",
       "      <td>0.866154</td>\n",
       "      <td>0.719494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748098e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2671.870168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.360647</td>\n",
       "      <td>0.919929</td>\n",
       "      <td>18974</td>\n",
       "      <td>0.488636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>856</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.704283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748098e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2752.087377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.357261</td>\n",
       "      <td>0.922177</td>\n",
       "      <td>19549</td>\n",
       "      <td>0.541114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>882</td>\n",
       "      <td>0.866923</td>\n",
       "      <td>0.731646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748098e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2832.733215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.378829</td>\n",
       "      <td>0.900282</td>\n",
       "      <td>20124</td>\n",
       "      <td>0.552743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>908</td>\n",
       "      <td>0.836923</td>\n",
       "      <td>0.726512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748098e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2913.224520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.357107</td>\n",
       "      <td>0.924119</td>\n",
       "      <td>20699</td>\n",
       "      <td>0.564767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>934</td>\n",
       "      <td>0.870769</td>\n",
       "      <td>0.744443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748098e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2994.108846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.353736</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>21274</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>960</td>\n",
       "      <td>0.856154</td>\n",
       "      <td>0.727635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748098e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3074.855123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344503</td>\n",
       "      <td>0.923284</td>\n",
       "      <td>21849</td>\n",
       "      <td>0.539084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>986</td>\n",
       "      <td>0.868462</td>\n",
       "      <td>0.731184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748098e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3155.067250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.345952</td>\n",
       "      <td>0.923146</td>\n",
       "      <td>22424</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1012</td>\n",
       "      <td>0.868462</td>\n",
       "      <td>0.733573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748098e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3235.681528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.371774</td>\n",
       "      <td>0.900943</td>\n",
       "      <td>22999</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1038</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.731722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.748098e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      optim/grad_norm_postclip  train/loss     _runtime  optim/lr  val/loss  \\\n",
       "24                         NaN         NaN    90.331943       NaN  0.423628   \n",
       "50                         NaN         NaN   171.148362       NaN  0.484767   \n",
       "76                         NaN         NaN   251.848982       NaN  0.475894   \n",
       "102                        NaN         NaN   333.917840       NaN  0.408851   \n",
       "128                        NaN         NaN   413.993400       NaN  0.393506   \n",
       "154                        NaN         NaN   495.125075       NaN  0.394339   \n",
       "180                        NaN         NaN   575.901231       NaN  0.437327   \n",
       "206                        NaN         NaN   655.830817       NaN  0.388706   \n",
       "232                        NaN         NaN   736.662869       NaN  0.384982   \n",
       "258                        NaN         NaN   816.903189       NaN  0.392373   \n",
       "284                        NaN         NaN   897.532951       NaN  0.418869   \n",
       "310                        NaN         NaN   978.534050       NaN  0.381025   \n",
       "336                        NaN         NaN  1058.626954       NaN  0.381694   \n",
       "362                        NaN         NaN  1139.106589       NaN  0.368728   \n",
       "388                        NaN         NaN  1219.644784       NaN  0.366494   \n",
       "414                        NaN         NaN  1300.358550       NaN  0.367841   \n",
       "440                        NaN         NaN  1380.871074       NaN  0.374723   \n",
       "466                        NaN         NaN  1461.261566       NaN  0.367390   \n",
       "492                        NaN         NaN  1542.415384       NaN  0.367741   \n",
       "518                        NaN         NaN  1622.752337       NaN  0.355994   \n",
       "544                        NaN         NaN  1703.204886       NaN  0.364386   \n",
       "570                        NaN         NaN  1783.678488       NaN  0.365489   \n",
       "596                        NaN         NaN  1864.436327       NaN  0.364093   \n",
       "622                        NaN         NaN  1945.375028       NaN  0.350609   \n",
       "648                        NaN         NaN  2026.038777       NaN  0.373286   \n",
       "674                        NaN         NaN  2106.984787       NaN  0.349313   \n",
       "700                        NaN         NaN  2187.649082       NaN  0.370402   \n",
       "726                        NaN         NaN  2268.608411       NaN  0.357784   \n",
       "752                        NaN         NaN  2349.287016       NaN  0.341467   \n",
       "778                        NaN         NaN  2430.125920       NaN  0.377868   \n",
       "804                        NaN         NaN  2510.835882       NaN  0.380593   \n",
       "830                        NaN         NaN  2591.432219       NaN  0.347539   \n",
       "856                        NaN         NaN  2671.870168       NaN  0.360647   \n",
       "882                        NaN         NaN  2752.087377       NaN  0.357261   \n",
       "908                        NaN         NaN  2832.733215       NaN  0.378829   \n",
       "934                        NaN         NaN  2913.224520       NaN  0.357107   \n",
       "960                        NaN         NaN  2994.108846       NaN  0.353736   \n",
       "986                        NaN         NaN  3074.855123       NaN  0.344503   \n",
       "1012                       NaN         NaN  3155.067250       NaN  0.345952   \n",
       "1038                       NaN         NaN  3235.681528       NaN  0.371774   \n",
       "\n",
       "      val/f1_class_0  trainer/global_step  val/f1_class_1  \\\n",
       "24          0.902896                  574        0.095238   \n",
       "50          0.860174                 1149        0.448669   \n",
       "76          0.863351                 1724        0.465028   \n",
       "102         0.910944                 2299        0.413994   \n",
       "128         0.915863                 2874        0.396226   \n",
       "154         0.913526                 3449        0.434783   \n",
       "180         0.906987                 4024        0.187266   \n",
       "206         0.916630                 4599        0.381877   \n",
       "232         0.916044                 5174        0.412308   \n",
       "258         0.914031                 5749        0.456338   \n",
       "284         0.899403                 6324        0.482269   \n",
       "310         0.916993                 6899        0.361204   \n",
       "336         0.917247                 7474        0.375000   \n",
       "362         0.919469                 8049        0.464706   \n",
       "388         0.916593                 8624        0.409938   \n",
       "414         0.916890                 9199        0.486188   \n",
       "440         0.918261                 9774        0.373333   \n",
       "466         0.919037                10349        0.412698   \n",
       "492         0.915556                10924        0.457143   \n",
       "518         0.920691                11499        0.478134   \n",
       "544         0.913960                12074        0.391304   \n",
       "570         0.918090                12649        0.410095   \n",
       "596         0.915069                13224        0.546341   \n",
       "622         0.924113                13799        0.546917   \n",
       "648         0.918190                14374        0.377483   \n",
       "674         0.921700                14949        0.520548   \n",
       "700         0.901212                15524        0.533040   \n",
       "726         0.919085                16099        0.435583   \n",
       "752         0.921826                16674        0.552972   \n",
       "778         0.922203                17249        0.429487   \n",
       "804         0.924570                17824        0.486486   \n",
       "830         0.922321                18399        0.516667   \n",
       "856         0.919929                18974        0.488636   \n",
       "882         0.922177                19549        0.541114   \n",
       "908         0.900282                20124        0.552743   \n",
       "934         0.924119                20699        0.564767   \n",
       "960         0.914729                21274        0.540541   \n",
       "986         0.923284                21849        0.539084   \n",
       "1012        0.923146                22424        0.544000   \n",
       "1038        0.900943                22999        0.562500   \n",
       "\n",
       "      optim/grad_norm_preclip  epoch  train/f1_macro  _step   val/acc  \\\n",
       "24                        NaN     24             NaN     24  0.824615   \n",
       "50                        NaN     49             NaN     50  0.776923   \n",
       "76                        NaN     74             NaN     76  0.782308   \n",
       "102                       NaN     99             NaN    102  0.845385   \n",
       "128                       NaN    124             NaN    128  0.852308   \n",
       "154                       NaN    149             NaN    154  0.850000   \n",
       "180                       NaN    174             NaN    180  0.833077   \n",
       "206                       NaN    199             NaN    206  0.853077   \n",
       "232                       NaN    224             NaN    232  0.853077   \n",
       "258                       NaN    249             NaN    258  0.851538   \n",
       "284                       NaN    274             NaN    284  0.831538   \n",
       "310                       NaN    299             NaN    310  0.853077   \n",
       "336                       NaN    324             NaN    336  0.853846   \n",
       "362                       NaN    349             NaN    362  0.860000   \n",
       "388                       NaN    374             NaN    388  0.853846   \n",
       "414                       NaN    399             NaN    414  0.856923   \n",
       "440                       NaN    424             NaN    440  0.855385   \n",
       "466                       NaN    449             NaN    466  0.857692   \n",
       "492                       NaN    474             NaN    492  0.853846   \n",
       "518                       NaN    499             NaN    518  0.862308   \n",
       "544                       NaN    524             NaN    544  0.849231   \n",
       "570                       NaN    549             NaN    570  0.856154   \n",
       "596                       NaN    574             NaN    596  0.856923   \n",
       "622                       NaN    599             NaN    622  0.870000   \n",
       "648                       NaN    624             NaN    648  0.855385   \n",
       "674                       NaN    649             NaN    674  0.865385   \n",
       "700                       NaN    674             NaN    700  0.836923   \n",
       "726                       NaN    699             NaN    726  0.858462   \n",
       "752                       NaN    724             NaN    752  0.866923   \n",
       "778                       NaN    749             NaN    778  0.863077   \n",
       "804                       NaN    774             NaN    804  0.868462   \n",
       "830                       NaN    799             NaN    830  0.866154   \n",
       "856                       NaN    824             NaN    856  0.861538   \n",
       "882                       NaN    849             NaN    882  0.866923   \n",
       "908                       NaN    874             NaN    908  0.836923   \n",
       "934                       NaN    899             NaN    934  0.870769   \n",
       "960                       NaN    924             NaN    960  0.856154   \n",
       "986                       NaN    949             NaN    986  0.868462   \n",
       "1012                      NaN    974             NaN   1012  0.868462   \n",
       "1038                      NaN    999             NaN   1038  0.838462   \n",
       "\n",
       "      val/f1_macro  train/acc  train/f1_class_1  train/f1_class_0  \\\n",
       "24        0.499067        NaN               NaN               NaN   \n",
       "50        0.654421        NaN               NaN               NaN   \n",
       "76        0.664190        NaN               NaN               NaN   \n",
       "102       0.662469        NaN               NaN               NaN   \n",
       "128       0.656045        NaN               NaN               NaN   \n",
       "154       0.674154        NaN               NaN               NaN   \n",
       "180       0.547126        NaN               NaN               NaN   \n",
       "206       0.649254        NaN               NaN               NaN   \n",
       "232       0.664176        NaN               NaN               NaN   \n",
       "258       0.685185        NaN               NaN               NaN   \n",
       "284       0.690836        NaN               NaN               NaN   \n",
       "310       0.639098        NaN               NaN               NaN   \n",
       "336       0.646124        NaN               NaN               NaN   \n",
       "362       0.692087        NaN               NaN               NaN   \n",
       "388       0.663266        NaN               NaN               NaN   \n",
       "414       0.701539        NaN               NaN               NaN   \n",
       "440       0.645797        NaN               NaN               NaN   \n",
       "466       0.665868        NaN               NaN               NaN   \n",
       "492       0.686349        NaN               NaN               NaN   \n",
       "518       0.699413        NaN               NaN               NaN   \n",
       "544       0.652632        NaN               NaN               NaN   \n",
       "570       0.664092        NaN               NaN               NaN   \n",
       "596       0.730705        NaN               NaN               NaN   \n",
       "622       0.735515        NaN               NaN               NaN   \n",
       "648       0.647837        NaN               NaN               NaN   \n",
       "674       0.721124        NaN               NaN               NaN   \n",
       "700       0.717126        NaN               NaN               NaN   \n",
       "726       0.677334        NaN               NaN               NaN   \n",
       "752       0.737399        NaN               NaN               NaN   \n",
       "778       0.675845        NaN               NaN               NaN   \n",
       "804       0.705528        NaN               NaN               NaN   \n",
       "830       0.719494        NaN               NaN               NaN   \n",
       "856       0.704283        NaN               NaN               NaN   \n",
       "882       0.731646        NaN               NaN               NaN   \n",
       "908       0.726512        NaN               NaN               NaN   \n",
       "934       0.744443        NaN               NaN               NaN   \n",
       "960       0.727635        NaN               NaN               NaN   \n",
       "986       0.731184        NaN               NaN               NaN   \n",
       "1012      0.733573        NaN               NaN               NaN   \n",
       "1038      0.731722        NaN               NaN               NaN   \n",
       "\n",
       "        _timestamp  \n",
       "24    1.748095e+09  \n",
       "50    1.748095e+09  \n",
       "76    1.748095e+09  \n",
       "102   1.748095e+09  \n",
       "128   1.748095e+09  \n",
       "154   1.748095e+09  \n",
       "180   1.748096e+09  \n",
       "206   1.748096e+09  \n",
       "232   1.748096e+09  \n",
       "258   1.748096e+09  \n",
       "284   1.748096e+09  \n",
       "310   1.748096e+09  \n",
       "336   1.748096e+09  \n",
       "362   1.748096e+09  \n",
       "388   1.748096e+09  \n",
       "414   1.748096e+09  \n",
       "440   1.748096e+09  \n",
       "466   1.748096e+09  \n",
       "492   1.748096e+09  \n",
       "518   1.748097e+09  \n",
       "544   1.748097e+09  \n",
       "570   1.748097e+09  \n",
       "596   1.748097e+09  \n",
       "622   1.748097e+09  \n",
       "648   1.748097e+09  \n",
       "674   1.748097e+09  \n",
       "700   1.748097e+09  \n",
       "726   1.748097e+09  \n",
       "752   1.748097e+09  \n",
       "778   1.748097e+09  \n",
       "804   1.748097e+09  \n",
       "830   1.748098e+09  \n",
       "856   1.748098e+09  \n",
       "882   1.748098e+09  \n",
       "908   1.748098e+09  \n",
       "934   1.748098e+09  \n",
       "960   1.748098e+09  \n",
       "986   1.748098e+09  \n",
       "1012  1.748098e+09  \n",
       "1038  1.748098e+09  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals[~vals[\"val/f1_macro\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee842803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [06:49<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get all runs in the project\n",
    "runs = api.runs(f\"{ENTITY}/{PROJECT}\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for run in tqdm(runs):\n",
    "    try:\n",
    "\n",
    "        if run.state in [\"failed\", \"crashed\"]:\n",
    "            continue\n",
    "        # Load history (all metrics per step/epoch)\n",
    "        history = run.history(samples=10000)  # increase samples if needed\n",
    "        \n",
    "        if \"val/f1_macro\" not in history.columns:\n",
    "            continue  # skip runs without F1\n",
    "        \n",
    "        # Find index of best val_f1\n",
    "        best_idx = history[\"val/f1_macro\"].idxmax()\n",
    "        best_row = history.loc[best_idx]\n",
    "\n",
    "        tags = run.tags\n",
    "\n",
    "        log_files = [f for f in run.files() if f.name == \"output.log\"]\n",
    "        log_str = log_files[0].download(replace=True).read()\n",
    "        if log_files:\n",
    "            train_params = parse_param_count(log_str)\n",
    "        else:\n",
    "            train_params = None\n",
    "\n",
    "        results_dict = {\n",
    "            \"run_id\": run.id,\n",
    "            \"run_name\": run.name,\n",
    "            \"tags\": \", \".join(tags),\n",
    "            \"epoch\": best_row.get(\"epoch\", best_idx),\n",
    "            \"val_f1_macro\": best_row.get(\"val/f1_macro\", None),\n",
    "            \"val_loss\": best_row.get(\"val/loss\", None),\n",
    "            \"val_accuracy\": best_row.get(\"val/acc\", None),\n",
    "            \"val_f1_class_1\": best_row.get(\"val/f1_class_1\",None),\n",
    "            \"val_f1_class_0\": best_row.get(\"val/f1_class_0\",None),\n",
    "            \"runtime_sec\": run.summary.get(\"_runtime\", None),\n",
    "            \"total_epochs\": history[\"epoch\"].max().item() + 1,\n",
    "            \"trainable_params\": train_params,\n",
    "            \"timestamp\": run.created_at,\n",
    "        }\n",
    "\n",
    "        raw_config = run._attrs.get(\"config\", {})\n",
    "        flat_config = flatten_config(raw_config)\n",
    "\n",
    "        # Output sample\n",
    "        for k, v in flat_config.items():\n",
    "            if \"logger\" not in k and \"output_dir\" not in k and \"launch_cmd\" not in k and \"repo_root\" not in k and \"username\" not in k and \"data.root\" not in k:\n",
    "                results_dict[k] = v\n",
    "\n",
    "        results.append(results_dict)\n",
    "    except Exception as e:\n",
    "        print(f\"Error with run {run.name}: {e}\")\n",
    "\n",
    "# Convert to DataFrame for sorting/filtering\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79bcf083",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.tags==\"debug\"].index,axis=0,inplace=True)\n",
    "df.drop(df[df.total_epochs == 10].index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8870779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part(tags):\n",
    "    if \"part1\" in tags or \"part_1\" in tags:\n",
    "        return \"part_1\"\n",
    "    elif \"part2a\" in tags:\n",
    "        return \"part_2a\"\n",
    "    elif \"part2b\" in tags:\n",
    "        return \"part_2b\"\n",
    "    elif \"part2c\" in tags:\n",
    "        return \"part_2c\"\n",
    "    elif \"part3\" in tags:\n",
    "        return \"part_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d5be375",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"part\"] = df[\"tags\"].apply(get_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b39608e",
   "metadata": {},
   "source": [
    "## Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e474b8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_f1_macro</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1_class_1</th>\n",
       "      <th>val_f1_class_0</th>\n",
       "      <th>runtime_sec</th>\n",
       "      <th>total_epochs</th>\n",
       "      <th>trainable_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2td0ekfv</td>\n",
       "      <td>soft-bee-85</td>\n",
       "      <td>baseline, fft, kaggle, lstm, part1, table1</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.880030</td>\n",
       "      <td>0.251406</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.802603</td>\n",
       "      <td>0.957457</td>\n",
       "      <td>2635.967565</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>v5isln9b</td>\n",
       "      <td>mild-bee-93</td>\n",
       "      <td>fft, lstm, part1, wd</td>\n",
       "      <td>949.0</td>\n",
       "      <td>0.878440</td>\n",
       "      <td>0.317623</td>\n",
       "      <td>0.926923</td>\n",
       "      <td>0.801670</td>\n",
       "      <td>0.955210</td>\n",
       "      <td>2647.010627</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>p99dbzsq</td>\n",
       "      <td>laced-feather-112</td>\n",
       "      <td>dropout, fft, lstm, part1</td>\n",
       "      <td>874.0</td>\n",
       "      <td>0.872077</td>\n",
       "      <td>0.319549</td>\n",
       "      <td>0.923846</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.953456</td>\n",
       "      <td>2759.538056</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gtmvhqv0</td>\n",
       "      <td>fallen-microwave-103</td>\n",
       "      <td>fft, hidden_dim, lstm, part1</td>\n",
       "      <td>549.0</td>\n",
       "      <td>0.871457</td>\n",
       "      <td>0.285607</td>\n",
       "      <td>0.924615</td>\n",
       "      <td>0.788793</td>\n",
       "      <td>0.954120</td>\n",
       "      <td>3902.806525</td>\n",
       "      <td>1000</td>\n",
       "      <td>340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>xe33zh99</td>\n",
       "      <td>northern-durian-248</td>\n",
       "      <td>cnn1d_medium, kaggle, lstm, part2b</td>\n",
       "      <td>449.0</td>\n",
       "      <td>0.870581</td>\n",
       "      <td>0.345199</td>\n",
       "      <td>0.924615</td>\n",
       "      <td>0.786957</td>\n",
       "      <td>0.954206</td>\n",
       "      <td>3794.414399</td>\n",
       "      <td>1000</td>\n",
       "      <td>145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lujwcq18</td>\n",
       "      <td>golden-universe-96</td>\n",
       "      <td>fft, lstm, part1, wd</td>\n",
       "      <td>599.0</td>\n",
       "      <td>0.870289</td>\n",
       "      <td>0.215348</td>\n",
       "      <td>0.926923</td>\n",
       "      <td>0.784580</td>\n",
       "      <td>0.955998</td>\n",
       "      <td>2655.218461</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>s873xj2n</td>\n",
       "      <td>devout-microwave-143</td>\n",
       "      <td>fft, num_heads, part1, table1, tencoder</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.863343</td>\n",
       "      <td>0.862400</td>\n",
       "      <td>0.923846</td>\n",
       "      <td>0.772414</td>\n",
       "      <td>0.954273</td>\n",
       "      <td>5889.564050</td>\n",
       "      <td>1000</td>\n",
       "      <td>563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>3lg8jawa</td>\n",
       "      <td>fluent-spaceship-252</td>\n",
       "      <td>cnn1d_large, lstm, part2b</td>\n",
       "      <td>724.0</td>\n",
       "      <td>0.860526</td>\n",
       "      <td>0.482502</td>\n",
       "      <td>0.916154</td>\n",
       "      <td>0.772443</td>\n",
       "      <td>0.948609</td>\n",
       "      <td>3881.166162</td>\n",
       "      <td>1000</td>\n",
       "      <td>188000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8na956dj</td>\n",
       "      <td>sage-oath-106</td>\n",
       "      <td>dropout, fft, lstm, part1</td>\n",
       "      <td>649.0</td>\n",
       "      <td>0.853587</td>\n",
       "      <td>0.376574</td>\n",
       "      <td>0.913846</td>\n",
       "      <td>0.759657</td>\n",
       "      <td>0.947516</td>\n",
       "      <td>2713.346854</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>n316o9sh</td>\n",
       "      <td>dark-durian-111</td>\n",
       "      <td>baseline, fft, part1, tencoder</td>\n",
       "      <td>724.0</td>\n",
       "      <td>0.850470</td>\n",
       "      <td>0.969485</td>\n",
       "      <td>0.912308</td>\n",
       "      <td>0.754310</td>\n",
       "      <td>0.946629</td>\n",
       "      <td>6326.859362</td>\n",
       "      <td>1000</td>\n",
       "      <td>563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>ueba181e</td>\n",
       "      <td>vibrant-firebrand-338</td>\n",
       "      <td>baseline, conv1d, fft, fold_1, part1</td>\n",
       "      <td>474.0</td>\n",
       "      <td>0.847948</td>\n",
       "      <td>0.656264</td>\n",
       "      <td>0.909028</td>\n",
       "      <td>0.751576</td>\n",
       "      <td>0.944319</td>\n",
       "      <td>2682.802614</td>\n",
       "      <td>1000</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>fv9amftf</td>\n",
       "      <td>gentle-violet-326</td>\n",
       "      <td>kaggle, learned_pool, lstm_att, part2d, part3a...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.847316</td>\n",
       "      <td>0.414346</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.745370</td>\n",
       "      <td>0.949262</td>\n",
       "      <td>3079.260911</td>\n",
       "      <td>50</td>\n",
       "      <td>464000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>84zm3uwa</td>\n",
       "      <td>comfy-snowball-132</td>\n",
       "      <td>fft, part1, tencoder, wd</td>\n",
       "      <td>974.0</td>\n",
       "      <td>0.846779</td>\n",
       "      <td>0.955033</td>\n",
       "      <td>0.914615</td>\n",
       "      <td>0.744828</td>\n",
       "      <td>0.948730</td>\n",
       "      <td>6370.567888</td>\n",
       "      <td>1000</td>\n",
       "      <td>563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>sg1yy2h1</td>\n",
       "      <td>devout-forest-121</td>\n",
       "      <td>fft, lr, part1, tencoder</td>\n",
       "      <td>724.0</td>\n",
       "      <td>0.846737</td>\n",
       "      <td>0.403651</td>\n",
       "      <td>0.908462</td>\n",
       "      <td>0.749474</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>6349.007331</td>\n",
       "      <td>1000</td>\n",
       "      <td>563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>18oedcex</td>\n",
       "      <td>tough-cherry-335</td>\n",
       "      <td>baseline, conv1d, fft, fold_0, part1</td>\n",
       "      <td>374.0</td>\n",
       "      <td>0.845524</td>\n",
       "      <td>0.708809</td>\n",
       "      <td>0.910644</td>\n",
       "      <td>0.745227</td>\n",
       "      <td>0.945821</td>\n",
       "      <td>2676.453955</td>\n",
       "      <td>1000</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>3ngqywle</td>\n",
       "      <td>vivid-breeze-137</td>\n",
       "      <td>conv1d, fft, kernels, part1, table1</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.845220</td>\n",
       "      <td>0.759532</td>\n",
       "      <td>0.910769</td>\n",
       "      <td>0.744493</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>2740.182147</td>\n",
       "      <td>1000</td>\n",
       "      <td>254000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>aebxdjrt</td>\n",
       "      <td>dashing-cosmos-337</td>\n",
       "      <td>baseline, fft, fold_2, part1, tencoder</td>\n",
       "      <td>824.0</td>\n",
       "      <td>0.845200</td>\n",
       "      <td>0.879339</td>\n",
       "      <td>0.910875</td>\n",
       "      <td>0.744371</td>\n",
       "      <td>0.946029</td>\n",
       "      <td>4840.027064</td>\n",
       "      <td>1000</td>\n",
       "      <td>563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>g41hf69e</td>\n",
       "      <td>dark-dew-328</td>\n",
       "      <td>baseline, fft, fold_0, lstm, part1</td>\n",
       "      <td>749.0</td>\n",
       "      <td>0.843601</td>\n",
       "      <td>0.369080</td>\n",
       "      <td>0.905334</td>\n",
       "      <td>0.745342</td>\n",
       "      <td>0.941860</td>\n",
       "      <td>2753.303172</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>wx5ra7zr</td>\n",
       "      <td>proud-lake-131</td>\n",
       "      <td>conv1d, fft, hidden_dim, part1</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0.843133</td>\n",
       "      <td>0.513450</td>\n",
       "      <td>0.906923</td>\n",
       "      <td>0.743100</td>\n",
       "      <td>0.943166</td>\n",
       "      <td>2954.490435</td>\n",
       "      <td>1000</td>\n",
       "      <td>577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2yg9l5qs</td>\n",
       "      <td>winter-aardvark-238</td>\n",
       "      <td>cnn1d_small, lstm, part2b</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.841447</td>\n",
       "      <td>0.478782</td>\n",
       "      <td>0.909231</td>\n",
       "      <td>0.737778</td>\n",
       "      <td>0.945116</td>\n",
       "      <td>3755.898387</td>\n",
       "      <td>1000</td>\n",
       "      <td>124000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       run_id               run_name  \\\n",
       "2    2td0ekfv            soft-bee-85   \n",
       "10   v5isln9b            mild-bee-93   \n",
       "27   p99dbzsq      laced-feather-112   \n",
       "20   gtmvhqv0   fallen-microwave-103   \n",
       "123  xe33zh99    northern-durian-248   \n",
       "13   lujwcq18     golden-universe-96   \n",
       "57   s873xj2n   devout-microwave-143   \n",
       "124  3lg8jawa   fluent-spaceship-252   \n",
       "23   8na956dj          sage-oath-106   \n",
       "26   n316o9sh        dark-durian-111   \n",
       "170  ueba181e  vibrant-firebrand-338   \n",
       "158  fv9amftf      gentle-violet-326   \n",
       "46   84zm3uwa     comfy-snowball-132   \n",
       "35   sg1yy2h1      devout-forest-121   \n",
       "167  18oedcex       tough-cherry-335   \n",
       "51   3ngqywle       vivid-breeze-137   \n",
       "169  aebxdjrt     dashing-cosmos-337   \n",
       "160  g41hf69e           dark-dew-328   \n",
       "45   wx5ra7zr         proud-lake-131   \n",
       "121  2yg9l5qs    winter-aardvark-238   \n",
       "\n",
       "                                                  tags  epoch  val_f1_macro  \\\n",
       "2           baseline, fft, kaggle, lstm, part1, table1  674.0      0.880030   \n",
       "10                                fft, lstm, part1, wd  949.0      0.878440   \n",
       "27                           dropout, fft, lstm, part1  874.0      0.872077   \n",
       "20                        fft, hidden_dim, lstm, part1  549.0      0.871457   \n",
       "123                 cnn1d_medium, kaggle, lstm, part2b  449.0      0.870581   \n",
       "13                                fft, lstm, part1, wd  599.0      0.870289   \n",
       "57             fft, num_heads, part1, table1, tencoder  999.0      0.863343   \n",
       "124                          cnn1d_large, lstm, part2b  724.0      0.860526   \n",
       "23                           dropout, fft, lstm, part1  649.0      0.853587   \n",
       "26                      baseline, fft, part1, tencoder  724.0      0.850470   \n",
       "170               baseline, conv1d, fft, fold_1, part1  474.0      0.847948   \n",
       "158  kaggle, learned_pool, lstm_att, part2d, part3a...   47.0      0.847316   \n",
       "46                            fft, part1, tencoder, wd  974.0      0.846779   \n",
       "35                            fft, lr, part1, tencoder  724.0      0.846737   \n",
       "167               baseline, conv1d, fft, fold_0, part1  374.0      0.845524   \n",
       "51                 conv1d, fft, kernels, part1, table1  674.0      0.845220   \n",
       "169             baseline, fft, fold_2, part1, tencoder  824.0      0.845200   \n",
       "160                 baseline, fft, fold_0, lstm, part1  749.0      0.843601   \n",
       "45                      conv1d, fft, hidden_dim, part1  199.0      0.843133   \n",
       "121                          cnn1d_small, lstm, part2b  674.0      0.841447   \n",
       "\n",
       "     val_loss  val_accuracy  val_f1_class_1  val_f1_class_0  runtime_sec  \\\n",
       "2    0.251406      0.930000        0.802603        0.957457  2635.967565   \n",
       "10   0.317623      0.926923        0.801670        0.955210  2647.010627   \n",
       "27   0.319549      0.923846        0.790698        0.953456  2759.538056   \n",
       "20   0.285607      0.924615        0.788793        0.954120  3902.806525   \n",
       "123  0.345199      0.924615        0.786957        0.954206  3794.414399   \n",
       "13   0.215348      0.926923        0.784580        0.955998  2655.218461   \n",
       "57   0.862400      0.923846        0.772414        0.954273  5889.564050   \n",
       "124  0.482502      0.916154        0.772443        0.948609  3881.166162   \n",
       "23   0.376574      0.913846        0.759657        0.947516  2713.346854   \n",
       "26   0.969485      0.912308        0.754310        0.946629  6326.859362   \n",
       "170  0.656264      0.909028        0.751576        0.944319  2682.802614   \n",
       "158  0.414346      0.915385        0.745370        0.949262  3079.260911   \n",
       "46   0.955033      0.914615        0.744828        0.948730  6370.567888   \n",
       "35   0.403651      0.908462        0.749474        0.944000  6349.007331   \n",
       "167  0.708809      0.910644        0.745227        0.945821  2676.453955   \n",
       "51   0.759532      0.910769        0.744493        0.945946  2740.182147   \n",
       "169  0.879339      0.910875        0.744371        0.946029  4840.027064   \n",
       "160  0.369080      0.905334        0.745342        0.941860  2753.303172   \n",
       "45   0.513450      0.906923        0.743100        0.943166  2954.490435   \n",
       "121  0.478782      0.909231        0.737778        0.945116  3755.898387   \n",
       "\n",
       "     total_epochs  trainable_params  \n",
       "2            1000             88400  \n",
       "10           1000             88400  \n",
       "27           1000             88400  \n",
       "20           1000            340000  \n",
       "123          1000            145000  \n",
       "13           1000             88400  \n",
       "57           1000            563000  \n",
       "124          1000            188000  \n",
       "23           1000             88400  \n",
       "26           1000            563000  \n",
       "170          1000            149000  \n",
       "158            50            464000  \n",
       "46           1000            563000  \n",
       "35           1000            563000  \n",
       "167          1000            149000  \n",
       "51           1000            254000  \n",
       "169          1000            563000  \n",
       "160          1000             88400  \n",
       "45           1000            577000  \n",
       "121          1000            124000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"val_f1_macro\",ascending=False).iloc[:,:12].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19c7ef8",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc24e4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(749.6410256410256)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.part == \"part_1\") & ((df[\"tags\"].str.contains(\"lstm\")) | (df[\"tags\"].str.contains(\"encoder\")) | (df[\"tags\"].str.contains(\"conv1d\")))][\"epoch\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47f0cf9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(259856.41025641025)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.part == \"part_1\") & ((df[\"tags\"].str.contains(\"lstm\")) | (df[\"tags\"].str.contains(\"encoder\")) | (df[\"tags\"].str.contains(\"conv1d\")))][\"trainable_params\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e15947e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_f1_macro</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1_class_1</th>\n",
       "      <th>val_f1_class_0</th>\n",
       "      <th>runtime_sec</th>\n",
       "      <th>total_epochs</th>\n",
       "      <th>trainable_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2td0ekfv</td>\n",
       "      <td>soft-bee-85</td>\n",
       "      <td>baseline, fft, kaggle, lstm, part1, table1</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.880030</td>\n",
       "      <td>0.251406</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.802603</td>\n",
       "      <td>0.957457</td>\n",
       "      <td>2635.967565</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>v5isln9b</td>\n",
       "      <td>mild-bee-93</td>\n",
       "      <td>fft, lstm, part1, wd</td>\n",
       "      <td>949.0</td>\n",
       "      <td>0.878440</td>\n",
       "      <td>0.317623</td>\n",
       "      <td>0.926923</td>\n",
       "      <td>0.801670</td>\n",
       "      <td>0.955210</td>\n",
       "      <td>2647.010627</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>p99dbzsq</td>\n",
       "      <td>laced-feather-112</td>\n",
       "      <td>dropout, fft, lstm, part1</td>\n",
       "      <td>874.0</td>\n",
       "      <td>0.872077</td>\n",
       "      <td>0.319549</td>\n",
       "      <td>0.923846</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.953456</td>\n",
       "      <td>2759.538056</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gtmvhqv0</td>\n",
       "      <td>fallen-microwave-103</td>\n",
       "      <td>fft, hidden_dim, lstm, part1</td>\n",
       "      <td>549.0</td>\n",
       "      <td>0.871457</td>\n",
       "      <td>0.285607</td>\n",
       "      <td>0.924615</td>\n",
       "      <td>0.788793</td>\n",
       "      <td>0.954120</td>\n",
       "      <td>3902.806525</td>\n",
       "      <td>1000</td>\n",
       "      <td>340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lujwcq18</td>\n",
       "      <td>golden-universe-96</td>\n",
       "      <td>fft, lstm, part1, wd</td>\n",
       "      <td>599.0</td>\n",
       "      <td>0.870289</td>\n",
       "      <td>0.215348</td>\n",
       "      <td>0.926923</td>\n",
       "      <td>0.784580</td>\n",
       "      <td>0.955998</td>\n",
       "      <td>2655.218461</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8na956dj</td>\n",
       "      <td>sage-oath-106</td>\n",
       "      <td>dropout, fft, lstm, part1</td>\n",
       "      <td>649.0</td>\n",
       "      <td>0.853587</td>\n",
       "      <td>0.376574</td>\n",
       "      <td>0.913846</td>\n",
       "      <td>0.759657</td>\n",
       "      <td>0.947516</td>\n",
       "      <td>2713.346854</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>g41hf69e</td>\n",
       "      <td>dark-dew-328</td>\n",
       "      <td>baseline, fft, fold_0, lstm, part1</td>\n",
       "      <td>749.0</td>\n",
       "      <td>0.843601</td>\n",
       "      <td>0.369080</td>\n",
       "      <td>0.905334</td>\n",
       "      <td>0.745342</td>\n",
       "      <td>0.941860</td>\n",
       "      <td>2753.303172</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>z6n9l2hy</td>\n",
       "      <td>worthy-brook-331</td>\n",
       "      <td>baseline, fft, fold_1, lstm, part1</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.840544</td>\n",
       "      <td>0.515463</td>\n",
       "      <td>0.902332</td>\n",
       "      <td>0.741284</td>\n",
       "      <td>0.939804</td>\n",
       "      <td>2751.515632</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>h7pnzxs6</td>\n",
       "      <td>rich-planet-333</td>\n",
       "      <td>baseline, fft, fold_2, lstm, part1</td>\n",
       "      <td>774.0</td>\n",
       "      <td>0.832774</td>\n",
       "      <td>0.381676</td>\n",
       "      <td>0.896329</td>\n",
       "      <td>0.729681</td>\n",
       "      <td>0.935866</td>\n",
       "      <td>2745.642053</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>kazlvbcw</td>\n",
       "      <td>vital-dust-116</td>\n",
       "      <td>fft, lstm, part1, weighted_sampler</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.548671</td>\n",
       "      <td>0.896923</td>\n",
       "      <td>0.723140</td>\n",
       "      <td>0.936673</td>\n",
       "      <td>2778.597105</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5x3v0hna</td>\n",
       "      <td>peach-eon-98</td>\n",
       "      <td>fft, lstm, normalize, part1</td>\n",
       "      <td>874.0</td>\n",
       "      <td>0.828272</td>\n",
       "      <td>0.765720</td>\n",
       "      <td>0.903077</td>\n",
       "      <td>0.714932</td>\n",
       "      <td>0.941613</td>\n",
       "      <td>2672.334527</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pe0zxu27</td>\n",
       "      <td>sweet-bee-88</td>\n",
       "      <td>fft, lr, lstm, part1</td>\n",
       "      <td>974.0</td>\n",
       "      <td>0.827018</td>\n",
       "      <td>0.336083</td>\n",
       "      <td>0.905385</td>\n",
       "      <td>0.710588</td>\n",
       "      <td>0.943448</td>\n",
       "      <td>2632.882214</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>wy7ots3v</td>\n",
       "      <td>copper-jazz-100</td>\n",
       "      <td>fft, hidden_dim, lstm, part1</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.824827</td>\n",
       "      <td>0.285052</td>\n",
       "      <td>0.896923</td>\n",
       "      <td>0.712446</td>\n",
       "      <td>0.937207</td>\n",
       "      <td>2379.633606</td>\n",
       "      <td>1000</td>\n",
       "      <td>23700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yix3i5q0</td>\n",
       "      <td>lyric-elevator-91</td>\n",
       "      <td>fft, lr, lstm, part1</td>\n",
       "      <td>974.0</td>\n",
       "      <td>0.743702</td>\n",
       "      <td>0.362950</td>\n",
       "      <td>0.868462</td>\n",
       "      <td>0.564885</td>\n",
       "      <td>0.922519</td>\n",
       "      <td>2643.305277</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       run_id              run_name  \\\n",
       "2    2td0ekfv           soft-bee-85   \n",
       "10   v5isln9b           mild-bee-93   \n",
       "27   p99dbzsq     laced-feather-112   \n",
       "20   gtmvhqv0  fallen-microwave-103   \n",
       "13   lujwcq18    golden-universe-96   \n",
       "23   8na956dj         sage-oath-106   \n",
       "160  g41hf69e          dark-dew-328   \n",
       "163  z6n9l2hy      worthy-brook-331   \n",
       "165  h7pnzxs6       rich-planet-333   \n",
       "30   kazlvbcw        vital-dust-116   \n",
       "15   5x3v0hna          peach-eon-98   \n",
       "5    pe0zxu27          sweet-bee-88   \n",
       "17   wy7ots3v       copper-jazz-100   \n",
       "8    yix3i5q0     lyric-elevator-91   \n",
       "\n",
       "                                           tags  epoch  val_f1_macro  \\\n",
       "2    baseline, fft, kaggle, lstm, part1, table1  674.0      0.880030   \n",
       "10                         fft, lstm, part1, wd  949.0      0.878440   \n",
       "27                    dropout, fft, lstm, part1  874.0      0.872077   \n",
       "20                 fft, hidden_dim, lstm, part1  549.0      0.871457   \n",
       "13                         fft, lstm, part1, wd  599.0      0.870289   \n",
       "23                    dropout, fft, lstm, part1  649.0      0.853587   \n",
       "160          baseline, fft, fold_0, lstm, part1  749.0      0.843601   \n",
       "163          baseline, fft, fold_1, lstm, part1  999.0      0.840544   \n",
       "165          baseline, fft, fold_2, lstm, part1  774.0      0.832774   \n",
       "30           fft, lstm, part1, weighted_sampler  999.0      0.829907   \n",
       "15                  fft, lstm, normalize, part1  874.0      0.828272   \n",
       "5                          fft, lr, lstm, part1  974.0      0.827018   \n",
       "17                 fft, hidden_dim, lstm, part1  999.0      0.824827   \n",
       "8                          fft, lr, lstm, part1  974.0      0.743702   \n",
       "\n",
       "     val_loss  val_accuracy  val_f1_class_1  val_f1_class_0  runtime_sec  \\\n",
       "2    0.251406      0.930000        0.802603        0.957457  2635.967565   \n",
       "10   0.317623      0.926923        0.801670        0.955210  2647.010627   \n",
       "27   0.319549      0.923846        0.790698        0.953456  2759.538056   \n",
       "20   0.285607      0.924615        0.788793        0.954120  3902.806525   \n",
       "13   0.215348      0.926923        0.784580        0.955998  2655.218461   \n",
       "23   0.376574      0.913846        0.759657        0.947516  2713.346854   \n",
       "160  0.369080      0.905334        0.745342        0.941860  2753.303172   \n",
       "163  0.515463      0.902332        0.741284        0.939804  2751.515632   \n",
       "165  0.381676      0.896329        0.729681        0.935866  2745.642053   \n",
       "30   0.548671      0.896923        0.723140        0.936673  2778.597105   \n",
       "15   0.765720      0.903077        0.714932        0.941613  2672.334527   \n",
       "5    0.336083      0.905385        0.710588        0.943448  2632.882214   \n",
       "17   0.285052      0.896923        0.712446        0.937207  2379.633606   \n",
       "8    0.362950      0.868462        0.564885        0.922519  2643.305277   \n",
       "\n",
       "     total_epochs  trainable_params  \n",
       "2            1000             88400  \n",
       "10           1000             88400  \n",
       "27           1000             88400  \n",
       "20           1000            340000  \n",
       "13           1000             88400  \n",
       "23           1000             88400  \n",
       "160          1000             88400  \n",
       "163          1000             88400  \n",
       "165          1000             88400  \n",
       "30           1000             88400  \n",
       "15           1000             88400  \n",
       "5            1000             88400  \n",
       "17           1000             23700  \n",
       "8            1000             88400  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.part == \"part_1\") & (df[\"tags\"].str.contains(\"lstm\"))].iloc[:,:12].sort_values(by=\"val_f1_macro\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3832619a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_f1_macro</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1_class_1</th>\n",
       "      <th>val_f1_class_0</th>\n",
       "      <th>runtime_sec</th>\n",
       "      <th>total_epochs</th>\n",
       "      <th>trainable_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>s873xj2n</td>\n",
       "      <td>devout-microwave-143</td>\n",
       "      <td>fft, num_heads, part1, table1, tencoder</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.863343</td>\n",
       "      <td>0.862400</td>\n",
       "      <td>0.923846</td>\n",
       "      <td>0.772414</td>\n",
       "      <td>0.954273</td>\n",
       "      <td>5889.564050</td>\n",
       "      <td>1000</td>\n",
       "      <td>563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>n316o9sh</td>\n",
       "      <td>dark-durian-111</td>\n",
       "      <td>baseline, fft, part1, tencoder</td>\n",
       "      <td>724.0</td>\n",
       "      <td>0.850470</td>\n",
       "      <td>0.969485</td>\n",
       "      <td>0.912308</td>\n",
       "      <td>0.754310</td>\n",
       "      <td>0.946629</td>\n",
       "      <td>6326.859362</td>\n",
       "      <td>1000</td>\n",
       "      <td>563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>84zm3uwa</td>\n",
       "      <td>comfy-snowball-132</td>\n",
       "      <td>fft, part1, tencoder, wd</td>\n",
       "      <td>974.0</td>\n",
       "      <td>0.846779</td>\n",
       "      <td>0.955033</td>\n",
       "      <td>0.914615</td>\n",
       "      <td>0.744828</td>\n",
       "      <td>0.948730</td>\n",
       "      <td>6370.567888</td>\n",
       "      <td>1000</td>\n",
       "      <td>563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>sg1yy2h1</td>\n",
       "      <td>devout-forest-121</td>\n",
       "      <td>fft, lr, part1, tencoder</td>\n",
       "      <td>724.0</td>\n",
       "      <td>0.846737</td>\n",
       "      <td>0.403651</td>\n",
       "      <td>0.908462</td>\n",
       "      <td>0.749474</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>6349.007331</td>\n",
       "      <td>1000</td>\n",
       "      <td>563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>aebxdjrt</td>\n",
       "      <td>dashing-cosmos-337</td>\n",
       "      <td>baseline, fft, fold_2, part1, tencoder</td>\n",
       "      <td>824.0</td>\n",
       "      <td>0.845200</td>\n",
       "      <td>0.879339</td>\n",
       "      <td>0.910875</td>\n",
       "      <td>0.744371</td>\n",
       "      <td>0.946029</td>\n",
       "      <td>4840.027064</td>\n",
       "      <td>1000</td>\n",
       "      <td>563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>flnd4l04</td>\n",
       "      <td>fragrant-energy-141</td>\n",
       "      <td>fft, normalize, part1, tencoder</td>\n",
       "      <td>474.0</td>\n",
       "      <td>0.839254</td>\n",
       "      <td>0.941781</td>\n",
       "      <td>0.908462</td>\n",
       "      <td>0.733781</td>\n",
       "      <td>0.944728</td>\n",
       "      <td>6414.621313</td>\n",
       "      <td>1000</td>\n",
       "      <td>563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>fq7no0nx</td>\n",
       "      <td>hardy-sun-332</td>\n",
       "      <td>baseline, fft, fold_1, part1, tencoder</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0.835146</td>\n",
       "      <td>0.700709</td>\n",
       "      <td>0.904641</td>\n",
       "      <td>0.728111</td>\n",
       "      <td>0.942181</td>\n",
       "      <td>4787.855554</td>\n",
       "      <td>1000</td>\n",
       "      <td>563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>4ogfq6bc</td>\n",
       "      <td>driven-water-142</td>\n",
       "      <td>fft, hidden_dim, part1, tencoder</td>\n",
       "      <td>849.0</td>\n",
       "      <td>0.834545</td>\n",
       "      <td>1.058803</td>\n",
       "      <td>0.904615</td>\n",
       "      <td>0.726872</td>\n",
       "      <td>0.942218</td>\n",
       "      <td>5570.094973</td>\n",
       "      <td>1000</td>\n",
       "      <td>275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>o4gzbh3g</td>\n",
       "      <td>denim-sun-329</td>\n",
       "      <td>baseline, fft, fold_0, part1, tencoder</td>\n",
       "      <td>874.0</td>\n",
       "      <td>0.834013</td>\n",
       "      <td>1.206233</td>\n",
       "      <td>0.901178</td>\n",
       "      <td>0.728426</td>\n",
       "      <td>0.939599</td>\n",
       "      <td>4756.428375</td>\n",
       "      <td>1000</td>\n",
       "      <td>563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4yrpsv4a</td>\n",
       "      <td>worldly-sun-138</td>\n",
       "      <td>fft, part1, tencoder, wd</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.827652</td>\n",
       "      <td>1.173667</td>\n",
       "      <td>0.903077</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>6394.442290</td>\n",
       "      <td>1000</td>\n",
       "      <td>563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>xgpfe40p</td>\n",
       "      <td>fast-pond-128</td>\n",
       "      <td>fft, lr, part1, tencoder</td>\n",
       "      <td>724.0</td>\n",
       "      <td>0.770790</td>\n",
       "      <td>0.362061</td>\n",
       "      <td>0.858462</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.912548</td>\n",
       "      <td>6353.840023</td>\n",
       "      <td>1000</td>\n",
       "      <td>563000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       run_id              run_name                                     tags  \\\n",
       "57   s873xj2n  devout-microwave-143  fft, num_heads, part1, table1, tencoder   \n",
       "26   n316o9sh       dark-durian-111           baseline, fft, part1, tencoder   \n",
       "46   84zm3uwa    comfy-snowball-132                 fft, part1, tencoder, wd   \n",
       "35   sg1yy2h1     devout-forest-121                 fft, lr, part1, tencoder   \n",
       "169  aebxdjrt    dashing-cosmos-337   baseline, fft, fold_2, part1, tencoder   \n",
       "55   flnd4l04   fragrant-energy-141          fft, normalize, part1, tencoder   \n",
       "164  fq7no0nx         hardy-sun-332   baseline, fft, fold_1, part1, tencoder   \n",
       "56   4ogfq6bc      driven-water-142         fft, hidden_dim, part1, tencoder   \n",
       "161  o4gzbh3g         denim-sun-329   baseline, fft, fold_0, part1, tencoder   \n",
       "52   4yrpsv4a       worldly-sun-138                 fft, part1, tencoder, wd   \n",
       "42   xgpfe40p         fast-pond-128                 fft, lr, part1, tencoder   \n",
       "\n",
       "     epoch  val_f1_macro  val_loss  val_accuracy  val_f1_class_1  \\\n",
       "57   999.0      0.863343  0.862400      0.923846        0.772414   \n",
       "26   724.0      0.850470  0.969485      0.912308        0.754310   \n",
       "46   974.0      0.846779  0.955033      0.914615        0.744828   \n",
       "35   724.0      0.846737  0.403651      0.908462        0.749474   \n",
       "169  824.0      0.845200  0.879339      0.910875        0.744371   \n",
       "55   474.0      0.839254  0.941781      0.908462        0.733781   \n",
       "164  324.0      0.835146  0.700709      0.904641        0.728111   \n",
       "56   849.0      0.834545  1.058803      0.904615        0.726872   \n",
       "161  874.0      0.834013  1.206233      0.901178        0.728426   \n",
       "52   999.0      0.827652  1.173667      0.903077        0.713636   \n",
       "42   724.0      0.770790  0.362061      0.858462        0.629032   \n",
       "\n",
       "     val_f1_class_0  runtime_sec  total_epochs  trainable_params  \n",
       "57         0.954273  5889.564050          1000            563000  \n",
       "26         0.946629  6326.859362          1000            563000  \n",
       "46         0.948730  6370.567888          1000            563000  \n",
       "35         0.944000  6349.007331          1000            563000  \n",
       "169        0.946029  4840.027064          1000            563000  \n",
       "55         0.944728  6414.621313          1000            563000  \n",
       "164        0.942181  4787.855554          1000            563000  \n",
       "56         0.942218  5570.094973          1000            275000  \n",
       "161        0.939599  4756.428375          1000            563000  \n",
       "52         0.941667  6394.442290          1000            563000  \n",
       "42         0.912548  6353.840023          1000            563000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.part == \"part_1\") & (df[\"tags\"].str.contains(\"encoder\"))].iloc[:,:12].sort_values(by=\"val_f1_macro\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfd6241b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_f1_macro</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1_class_1</th>\n",
       "      <th>val_f1_class_0</th>\n",
       "      <th>runtime_sec</th>\n",
       "      <th>total_epochs</th>\n",
       "      <th>trainable_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>ueba181e</td>\n",
       "      <td>vibrant-firebrand-338</td>\n",
       "      <td>baseline, conv1d, fft, fold_1, part1</td>\n",
       "      <td>474.0</td>\n",
       "      <td>0.847948</td>\n",
       "      <td>0.656264</td>\n",
       "      <td>0.909028</td>\n",
       "      <td>0.751576</td>\n",
       "      <td>0.944319</td>\n",
       "      <td>2682.802614</td>\n",
       "      <td>1000</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>18oedcex</td>\n",
       "      <td>tough-cherry-335</td>\n",
       "      <td>baseline, conv1d, fft, fold_0, part1</td>\n",
       "      <td>374.0</td>\n",
       "      <td>0.845524</td>\n",
       "      <td>0.708809</td>\n",
       "      <td>0.910644</td>\n",
       "      <td>0.745227</td>\n",
       "      <td>0.945821</td>\n",
       "      <td>2676.453955</td>\n",
       "      <td>1000</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>3ngqywle</td>\n",
       "      <td>vivid-breeze-137</td>\n",
       "      <td>conv1d, fft, kernels, part1, table1</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.845220</td>\n",
       "      <td>0.759532</td>\n",
       "      <td>0.910769</td>\n",
       "      <td>0.744493</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>2740.182147</td>\n",
       "      <td>1000</td>\n",
       "      <td>254000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>wx5ra7zr</td>\n",
       "      <td>proud-lake-131</td>\n",
       "      <td>conv1d, fft, hidden_dim, part1</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0.843133</td>\n",
       "      <td>0.513450</td>\n",
       "      <td>0.906923</td>\n",
       "      <td>0.743100</td>\n",
       "      <td>0.943166</td>\n",
       "      <td>2954.490435</td>\n",
       "      <td>1000</td>\n",
       "      <td>577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mn4tf2le</td>\n",
       "      <td>bumbling-plasma-120</td>\n",
       "      <td>conv1d, fft, lr, part1</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.841078</td>\n",
       "      <td>0.266486</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.741201</td>\n",
       "      <td>0.940954</td>\n",
       "      <td>2619.920066</td>\n",
       "      <td>1000</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>9zz06h10</td>\n",
       "      <td>robust-grass-135</td>\n",
       "      <td>conv1d, fft, kernels, part1</td>\n",
       "      <td>599.0</td>\n",
       "      <td>0.838104</td>\n",
       "      <td>0.768682</td>\n",
       "      <td>0.908462</td>\n",
       "      <td>0.731377</td>\n",
       "      <td>0.944831</td>\n",
       "      <td>2755.984013</td>\n",
       "      <td>1000</td>\n",
       "      <td>465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>h5n8xkci</td>\n",
       "      <td>smart-gorge-340</td>\n",
       "      <td>baseline, conv1d, fft, fold_2, part1</td>\n",
       "      <td>449.0</td>\n",
       "      <td>0.835815</td>\n",
       "      <td>0.712317</td>\n",
       "      <td>0.903025</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.940862</td>\n",
       "      <td>2697.722533</td>\n",
       "      <td>1000</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>9ydhm336</td>\n",
       "      <td>stellar-dream-134</td>\n",
       "      <td>conv1d, fft, kernels, part1</td>\n",
       "      <td>574.0</td>\n",
       "      <td>0.834807</td>\n",
       "      <td>0.944007</td>\n",
       "      <td>0.902308</td>\n",
       "      <td>0.729211</td>\n",
       "      <td>0.940404</td>\n",
       "      <td>2614.189849</td>\n",
       "      <td>1000</td>\n",
       "      <td>128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>oh6ya7xa</td>\n",
       "      <td>fresh-snow-123</td>\n",
       "      <td>conv1d, fft, part1, wd</td>\n",
       "      <td>574.0</td>\n",
       "      <td>0.832336</td>\n",
       "      <td>0.622202</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.722838</td>\n",
       "      <td>0.941833</td>\n",
       "      <td>2616.686718</td>\n",
       "      <td>1000</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>kabnumgc</td>\n",
       "      <td>floral-shape-117</td>\n",
       "      <td>conv1d, fft, lr, part1</td>\n",
       "      <td>899.0</td>\n",
       "      <td>0.831512</td>\n",
       "      <td>0.743604</td>\n",
       "      <td>0.896923</td>\n",
       "      <td>0.726531</td>\n",
       "      <td>0.936493</td>\n",
       "      <td>2609.875924</td>\n",
       "      <td>1000</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>af1yjrhj</td>\n",
       "      <td>leafy-bush-140</td>\n",
       "      <td>conv1d, fft, part1, weighted_sampler</td>\n",
       "      <td>924.0</td>\n",
       "      <td>0.829941</td>\n",
       "      <td>0.847772</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.717833</td>\n",
       "      <td>0.942049</td>\n",
       "      <td>2705.703943</td>\n",
       "      <td>1000</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lh6kyh6g</td>\n",
       "      <td>daily-paper-114</td>\n",
       "      <td>baseline, conv1d, fft, part1</td>\n",
       "      <td>874.0</td>\n",
       "      <td>0.829208</td>\n",
       "      <td>0.775038</td>\n",
       "      <td>0.901538</td>\n",
       "      <td>0.718062</td>\n",
       "      <td>0.940354</td>\n",
       "      <td>2616.368452</td>\n",
       "      <td>1000</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>gr4rhwij</td>\n",
       "      <td>eager-resonance-125</td>\n",
       "      <td>conv1d, fft, part1, wd</td>\n",
       "      <td>524.0</td>\n",
       "      <td>0.820095</td>\n",
       "      <td>0.631733</td>\n",
       "      <td>0.898462</td>\n",
       "      <td>0.701357</td>\n",
       "      <td>0.938832</td>\n",
       "      <td>2623.385606</td>\n",
       "      <td>1000</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>cu6odzyx</td>\n",
       "      <td>polished-silence-129</td>\n",
       "      <td>conv1d, fft, hidden_dim, part1</td>\n",
       "      <td>974.0</td>\n",
       "      <td>0.818376</td>\n",
       "      <td>0.898025</td>\n",
       "      <td>0.893846</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.935454</td>\n",
       "      <td>2504.945264</td>\n",
       "      <td>1000</td>\n",
       "      <td>39900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       run_id               run_name                                  tags  \\\n",
       "170  ueba181e  vibrant-firebrand-338  baseline, conv1d, fft, fold_1, part1   \n",
       "167  18oedcex       tough-cherry-335  baseline, conv1d, fft, fold_0, part1   \n",
       "51   3ngqywle       vivid-breeze-137   conv1d, fft, kernels, part1, table1   \n",
       "45   wx5ra7zr         proud-lake-131        conv1d, fft, hidden_dim, part1   \n",
       "34   mn4tf2le    bumbling-plasma-120                conv1d, fft, lr, part1   \n",
       "49   9zz06h10       robust-grass-135           conv1d, fft, kernels, part1   \n",
       "172  h5n8xkci        smart-gorge-340  baseline, conv1d, fft, fold_2, part1   \n",
       "48   9ydhm336      stellar-dream-134           conv1d, fft, kernels, part1   \n",
       "37   oh6ya7xa         fresh-snow-123                conv1d, fft, part1, wd   \n",
       "31   kabnumgc       floral-shape-117                conv1d, fft, lr, part1   \n",
       "54   af1yjrhj         leafy-bush-140  conv1d, fft, part1, weighted_sampler   \n",
       "28   lh6kyh6g        daily-paper-114          baseline, conv1d, fft, part1   \n",
       "39   gr4rhwij    eager-resonance-125                conv1d, fft, part1, wd   \n",
       "43   cu6odzyx   polished-silence-129        conv1d, fft, hidden_dim, part1   \n",
       "\n",
       "     epoch  val_f1_macro  val_loss  val_accuracy  val_f1_class_1  \\\n",
       "170  474.0      0.847948  0.656264      0.909028        0.751576   \n",
       "167  374.0      0.845524  0.708809      0.910644        0.745227   \n",
       "51   674.0      0.845220  0.759532      0.910769        0.744493   \n",
       "45   199.0      0.843133  0.513450      0.906923        0.743100   \n",
       "34   999.0      0.841078  0.266486      0.903846        0.741201   \n",
       "49   599.0      0.838104  0.768682      0.908462        0.731377   \n",
       "172  449.0      0.835815  0.712317      0.903025        0.730769   \n",
       "48   574.0      0.834807  0.944007      0.902308        0.729211   \n",
       "37   574.0      0.832336  0.622202      0.903846        0.722838   \n",
       "31   899.0      0.831512  0.743604      0.896923        0.726531   \n",
       "54   924.0      0.829941  0.847772      0.903846        0.717833   \n",
       "28   874.0      0.829208  0.775038      0.901538        0.718062   \n",
       "39   524.0      0.820095  0.631733      0.898462        0.701357   \n",
       "43   974.0      0.818376  0.898025      0.893846        0.701299   \n",
       "\n",
       "     val_f1_class_0  runtime_sec  total_epochs  trainable_params  \n",
       "170        0.944319  2682.802614          1000            149000  \n",
       "167        0.945821  2676.453955          1000            149000  \n",
       "51         0.945946  2740.182147          1000            254000  \n",
       "45         0.943166  2954.490435          1000            577000  \n",
       "34         0.940954  2619.920066          1000            149000  \n",
       "49         0.944831  2755.984013          1000            465000  \n",
       "172        0.940862  2697.722533          1000            149000  \n",
       "48         0.940404  2614.189849          1000            128000  \n",
       "37         0.941833  2616.686718          1000            149000  \n",
       "31         0.936493  2609.875924          1000            149000  \n",
       "54         0.942049  2705.703943          1000            149000  \n",
       "28         0.940354  2616.368452          1000            149000  \n",
       "39         0.938832  2623.385606          1000            149000  \n",
       "43         0.935454  2504.945264          1000             39900  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.part == \"part_1\") & (df[\"tags\"].str.contains(\"conv1d\"))].iloc[:,:12].sort_values(by=\"val_f1_macro\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71a6f047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_f1_macro</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1_class_1</th>\n",
       "      <th>val_f1_class_0</th>\n",
       "      <th>runtime_sec</th>\n",
       "      <th>total_epochs</th>\n",
       "      <th>trainable_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>vr0u2u3q</td>\n",
       "      <td>worldly-violet-110</td>\n",
       "      <td>fft, gat, hidden_dim, part1, table1</td>\n",
       "      <td>949.0</td>\n",
       "      <td>0.754566</td>\n",
       "      <td>0.370728</td>\n",
       "      <td>0.876154</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.927314</td>\n",
       "      <td>4408.092679</td>\n",
       "      <td>1000</td>\n",
       "      <td>430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>h20bdt1r</td>\n",
       "      <td>rich-wood-94</td>\n",
       "      <td>fft, gat, part1, wd</td>\n",
       "      <td>899.0</td>\n",
       "      <td>0.750798</td>\n",
       "      <td>0.388456</td>\n",
       "      <td>0.870769</td>\n",
       "      <td>0.577889</td>\n",
       "      <td>0.923706</td>\n",
       "      <td>3794.153726</td>\n",
       "      <td>1000</td>\n",
       "      <td>198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xh9fhf70</td>\n",
       "      <td>comfy-dawn-87</td>\n",
       "      <td>fft, gat, lr, part1</td>\n",
       "      <td>774.0</td>\n",
       "      <td>0.738268</td>\n",
       "      <td>0.377942</td>\n",
       "      <td>0.853077</td>\n",
       "      <td>0.564920</td>\n",
       "      <td>0.911615</td>\n",
       "      <td>3772.087685</td>\n",
       "      <td>1000</td>\n",
       "      <td>198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gara6unb</td>\n",
       "      <td>dazzling-hill-97</td>\n",
       "      <td>fft, gat, part1, wd</td>\n",
       "      <td>949.0</td>\n",
       "      <td>0.734562</td>\n",
       "      <td>0.369012</td>\n",
       "      <td>0.851538</td>\n",
       "      <td>0.558352</td>\n",
       "      <td>0.910772</td>\n",
       "      <td>3837.919780</td>\n",
       "      <td>1000</td>\n",
       "      <td>198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>vfrixc4j</td>\n",
       "      <td>devoted-capybara-357</td>\n",
       "      <td>fft, fold_0, gat, learned_pool, part1</td>\n",
       "      <td>649.0</td>\n",
       "      <td>0.734520</td>\n",
       "      <td>0.432012</td>\n",
       "      <td>0.859617</td>\n",
       "      <td>0.552283</td>\n",
       "      <td>0.916758</td>\n",
       "      <td>3492.618042</td>\n",
       "      <td>1000</td>\n",
       "      <td>218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>xmdu9ya6</td>\n",
       "      <td>sandy-sea-360</td>\n",
       "      <td>fft, fold_1, gat, learned_pool, part1</td>\n",
       "      <td>774.0</td>\n",
       "      <td>0.733785</td>\n",
       "      <td>0.676403</td>\n",
       "      <td>0.863311</td>\n",
       "      <td>0.548092</td>\n",
       "      <td>0.919478</td>\n",
       "      <td>3447.972215</td>\n",
       "      <td>1000</td>\n",
       "      <td>218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>fbv6jyow</td>\n",
       "      <td>visionary-planet-315</td>\n",
       "      <td>fft, gat, learned_pool, part1</td>\n",
       "      <td>699.0</td>\n",
       "      <td>0.733355</td>\n",
       "      <td>0.518170</td>\n",
       "      <td>0.869231</td>\n",
       "      <td>0.543011</td>\n",
       "      <td>0.923698</td>\n",
       "      <td>3576.004542</td>\n",
       "      <td>1000</td>\n",
       "      <td>218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ysr1v1jo</td>\n",
       "      <td>expert-darkness-139</td>\n",
       "      <td>fft, gat, part1, weighted_sampler</td>\n",
       "      <td>574.0</td>\n",
       "      <td>0.732460</td>\n",
       "      <td>0.413294</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.561028</td>\n",
       "      <td>0.903891</td>\n",
       "      <td>3918.134046</td>\n",
       "      <td>1000</td>\n",
       "      <td>198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>bqjk0nmq</td>\n",
       "      <td>volcanic-firebrand-339</td>\n",
       "      <td>baseline, fft, fold_1, gat, part1</td>\n",
       "      <td>574.0</td>\n",
       "      <td>0.727485</td>\n",
       "      <td>0.375386</td>\n",
       "      <td>0.848072</td>\n",
       "      <td>0.546207</td>\n",
       "      <td>0.908763</td>\n",
       "      <td>3138.975731</td>\n",
       "      <td>1000</td>\n",
       "      <td>198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>gvekxh9m</td>\n",
       "      <td>fearless-sea-133</td>\n",
       "      <td>distance_threshold, fft, gat, part1</td>\n",
       "      <td>424.0</td>\n",
       "      <td>0.725436</td>\n",
       "      <td>0.493470</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.543379</td>\n",
       "      <td>0.907493</td>\n",
       "      <td>4423.609002</td>\n",
       "      <td>1000</td>\n",
       "      <td>198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>958cmkea</td>\n",
       "      <td>glorious-feather-84</td>\n",
       "      <td>baseline, fft, gat, part1</td>\n",
       "      <td>749.0</td>\n",
       "      <td>0.724432</td>\n",
       "      <td>0.416225</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.907579</td>\n",
       "      <td>3757.224631</td>\n",
       "      <td>1000</td>\n",
       "      <td>198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tsh1vx37</td>\n",
       "      <td>glamorous-dawn-122</td>\n",
       "      <td>fft, gat, heads, part1</td>\n",
       "      <td>524.0</td>\n",
       "      <td>0.723663</td>\n",
       "      <td>0.393908</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.536817</td>\n",
       "      <td>0.910509</td>\n",
       "      <td>4157.100330</td>\n",
       "      <td>1000</td>\n",
       "      <td>298000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>q6qnay80</td>\n",
       "      <td>jolly-yogurt-341</td>\n",
       "      <td>baseline, fft, fold_2, gat, part1</td>\n",
       "      <td>974.0</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.417576</td>\n",
       "      <td>0.843916</td>\n",
       "      <td>0.531856</td>\n",
       "      <td>0.906345</td>\n",
       "      <td>3136.333012</td>\n",
       "      <td>1000</td>\n",
       "      <td>198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ko10rhr5</td>\n",
       "      <td>solar-butterfly-126</td>\n",
       "      <td>fft, gat, part1, pooling</td>\n",
       "      <td>849.0</td>\n",
       "      <td>0.718572</td>\n",
       "      <td>0.452323</td>\n",
       "      <td>0.844615</td>\n",
       "      <td>0.530233</td>\n",
       "      <td>0.906912</td>\n",
       "      <td>3912.552465</td>\n",
       "      <td>1000</td>\n",
       "      <td>198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>89cdmhh6</td>\n",
       "      <td>swept-leaf-343</td>\n",
       "      <td>fft, fold_0, gat, max_pool, part1</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.713916</td>\n",
       "      <td>0.417939</td>\n",
       "      <td>0.858693</td>\n",
       "      <td>0.510400</td>\n",
       "      <td>0.917431</td>\n",
       "      <td>3240.204720</td>\n",
       "      <td>1000</td>\n",
       "      <td>198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>v7pnulih</td>\n",
       "      <td>cool-resonance-130</td>\n",
       "      <td>fft, gat, part1, pooling</td>\n",
       "      <td>549.0</td>\n",
       "      <td>0.712326</td>\n",
       "      <td>0.392577</td>\n",
       "      <td>0.843846</td>\n",
       "      <td>0.517815</td>\n",
       "      <td>0.906838</td>\n",
       "      <td>3922.090185</td>\n",
       "      <td>1000</td>\n",
       "      <td>198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>l8up1xbu</td>\n",
       "      <td>lemon-feather-361</td>\n",
       "      <td>fft, fold_2, gat, learned_pool, part1</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.710416</td>\n",
       "      <td>0.450275</td>\n",
       "      <td>0.850381</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.911741</td>\n",
       "      <td>3464.081755</td>\n",
       "      <td>1000</td>\n",
       "      <td>218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>p4jzeqha</td>\n",
       "      <td>efficient-wildflower-101</td>\n",
       "      <td>batchnorm, fft, gat, part1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.704004</td>\n",
       "      <td>0.437080</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.496124</td>\n",
       "      <td>0.911884</td>\n",
       "      <td>3897.993803</td>\n",
       "      <td>1000</td>\n",
       "      <td>199000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>n0pmurwz</td>\n",
       "      <td>copper-smoke-118</td>\n",
       "      <td>fft, gat, heads, part1</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.699124</td>\n",
       "      <td>0.402833</td>\n",
       "      <td>0.844615</td>\n",
       "      <td>0.489899</td>\n",
       "      <td>0.908348</td>\n",
       "      <td>3706.688537</td>\n",
       "      <td>1000</td>\n",
       "      <td>99500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>kv2bjofo</td>\n",
       "      <td>fanciful-plasma-105</td>\n",
       "      <td>fft, gat, hidden_dim, part1</td>\n",
       "      <td>924.0</td>\n",
       "      <td>0.699003</td>\n",
       "      <td>0.434809</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.491315</td>\n",
       "      <td>0.906691</td>\n",
       "      <td>3641.053859</td>\n",
       "      <td>1000</td>\n",
       "      <td>95300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>zlicq64d</td>\n",
       "      <td>exalted-moon-350</td>\n",
       "      <td>fft, fold_2, gat, max_pool, part1</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.698970</td>\n",
       "      <td>0.394167</td>\n",
       "      <td>0.845532</td>\n",
       "      <td>0.488923</td>\n",
       "      <td>0.909017</td>\n",
       "      <td>3209.740574</td>\n",
       "      <td>1000</td>\n",
       "      <td>198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>ro8rpjan</td>\n",
       "      <td>resilient-sun-359</td>\n",
       "      <td>add_pool, fft, fold_2, gat, part1</td>\n",
       "      <td>399.0</td>\n",
       "      <td>0.696329</td>\n",
       "      <td>0.536485</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>0.486122</td>\n",
       "      <td>0.906536</td>\n",
       "      <td>3162.557350</td>\n",
       "      <td>1000</td>\n",
       "      <td>198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>7a74zkm7</td>\n",
       "      <td>classic-silence-336</td>\n",
       "      <td>baseline, fft, fold_0, gat, part1</td>\n",
       "      <td>574.0</td>\n",
       "      <td>0.690967</td>\n",
       "      <td>0.449806</td>\n",
       "      <td>0.804664</td>\n",
       "      <td>0.503521</td>\n",
       "      <td>0.878413</td>\n",
       "      <td>3146.851984</td>\n",
       "      <td>1000</td>\n",
       "      <td>198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>17aubfli</td>\n",
       "      <td>vital-tree-346</td>\n",
       "      <td>fft, fold_1, gat, max_pool, part1</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.687025</td>\n",
       "      <td>0.495004</td>\n",
       "      <td>0.852690</td>\n",
       "      <td>0.459322</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>3351.342251</td>\n",
       "      <td>1000</td>\n",
       "      <td>198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>jigeekhi</td>\n",
       "      <td>toasty-eon-356</td>\n",
       "      <td>add_pool, fft, fold_1, gat, part1</td>\n",
       "      <td>974.0</td>\n",
       "      <td>0.684162</td>\n",
       "      <td>0.684317</td>\n",
       "      <td>0.857770</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.918324</td>\n",
       "      <td>3170.529652</td>\n",
       "      <td>1000</td>\n",
       "      <td>198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>dczn67vd</td>\n",
       "      <td>rare-dust-136</td>\n",
       "      <td>distance_threshold, fft, gat, part1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.669648</td>\n",
       "      <td>0.458554</td>\n",
       "      <td>0.816923</td>\n",
       "      <td>0.449074</td>\n",
       "      <td>0.890221</td>\n",
       "      <td>3454.775759</td>\n",
       "      <td>1000</td>\n",
       "      <td>198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>333h0r8d</td>\n",
       "      <td>smart-music-353</td>\n",
       "      <td>add_pool, fft, fold_0, gat, part1</td>\n",
       "      <td>799.0</td>\n",
       "      <td>0.613558</td>\n",
       "      <td>1.281941</td>\n",
       "      <td>0.840914</td>\n",
       "      <td>0.317146</td>\n",
       "      <td>0.909970</td>\n",
       "      <td>3186.814104</td>\n",
       "      <td>1000</td>\n",
       "      <td>198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>opkb232y</td>\n",
       "      <td>fiery-rain-90</td>\n",
       "      <td>fft, gat, lr, part1</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.563487</td>\n",
       "      <td>0.416167</td>\n",
       "      <td>0.835385</td>\n",
       "      <td>0.218978</td>\n",
       "      <td>0.907997</td>\n",
       "      <td>3784.745855</td>\n",
       "      <td>1000</td>\n",
       "      <td>198000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       run_id                  run_name  \\\n",
       "25   vr0u2u3q        worldly-violet-110   \n",
       "11   h20bdt1r              rich-wood-94   \n",
       "4    xh9fhf70             comfy-dawn-87   \n",
       "14   gara6unb          dazzling-hill-97   \n",
       "187  vfrixc4j      devoted-capybara-357   \n",
       "190  xmdu9ya6             sandy-sea-360   \n",
       "149  fbv6jyow      visionary-planet-315   \n",
       "53   ysr1v1jo       expert-darkness-139   \n",
       "171  bqjk0nmq    volcanic-firebrand-339   \n",
       "47   gvekxh9m          fearless-sea-133   \n",
       "1    958cmkea       glorious-feather-84   \n",
       "36   tsh1vx37        glamorous-dawn-122   \n",
       "173  q6qnay80          jolly-yogurt-341   \n",
       "40   ko10rhr5       solar-butterfly-126   \n",
       "174  89cdmhh6            swept-leaf-343   \n",
       "44   v7pnulih        cool-resonance-130   \n",
       "191  l8up1xbu         lemon-feather-361   \n",
       "18   p4jzeqha  efficient-wildflower-101   \n",
       "32   n0pmurwz          copper-smoke-118   \n",
       "22   kv2bjofo       fanciful-plasma-105   \n",
       "182  zlicq64d          exalted-moon-350   \n",
       "189  ro8rpjan         resilient-sun-359   \n",
       "168  7a74zkm7       classic-silence-336   \n",
       "178  17aubfli            vital-tree-346   \n",
       "186  jigeekhi            toasty-eon-356   \n",
       "50   dczn67vd             rare-dust-136   \n",
       "184  333h0r8d           smart-music-353   \n",
       "7    opkb232y             fiery-rain-90   \n",
       "\n",
       "                                      tags  epoch  val_f1_macro  val_loss  \\\n",
       "25     fft, gat, hidden_dim, part1, table1  949.0      0.754566  0.370728   \n",
       "11                     fft, gat, part1, wd  899.0      0.750798  0.388456   \n",
       "4                      fft, gat, lr, part1  774.0      0.738268  0.377942   \n",
       "14                     fft, gat, part1, wd  949.0      0.734562  0.369012   \n",
       "187  fft, fold_0, gat, learned_pool, part1  649.0      0.734520  0.432012   \n",
       "190  fft, fold_1, gat, learned_pool, part1  774.0      0.733785  0.676403   \n",
       "149          fft, gat, learned_pool, part1  699.0      0.733355  0.518170   \n",
       "53       fft, gat, part1, weighted_sampler  574.0      0.732460  0.413294   \n",
       "171      baseline, fft, fold_1, gat, part1  574.0      0.727485  0.375386   \n",
       "47     distance_threshold, fft, gat, part1  424.0      0.725436  0.493470   \n",
       "1                baseline, fft, gat, part1  749.0      0.724432  0.416225   \n",
       "36                  fft, gat, heads, part1  524.0      0.723663  0.393908   \n",
       "173      baseline, fft, fold_2, gat, part1  974.0      0.719101  0.417576   \n",
       "40                fft, gat, part1, pooling  849.0      0.718572  0.452323   \n",
       "174      fft, fold_0, gat, max_pool, part1  674.0      0.713916  0.417939   \n",
       "44                fft, gat, part1, pooling  549.0      0.712326  0.392577   \n",
       "191  fft, fold_2, gat, learned_pool, part1  149.0      0.710416  0.450275   \n",
       "18              batchnorm, fft, gat, part1   24.0      0.704004  0.437080   \n",
       "32                  fft, gat, heads, part1   74.0      0.699124  0.402833   \n",
       "22             fft, gat, hidden_dim, part1  924.0      0.699003  0.434809   \n",
       "182      fft, fold_2, gat, max_pool, part1  999.0      0.698970  0.394167   \n",
       "189      add_pool, fft, fold_2, gat, part1  399.0      0.696329  0.536485   \n",
       "168      baseline, fft, fold_0, gat, part1  574.0      0.690967  0.449806   \n",
       "178      fft, fold_1, gat, max_pool, part1  149.0      0.687025  0.495004   \n",
       "186      add_pool, fft, fold_1, gat, part1  974.0      0.684162  0.684317   \n",
       "50     distance_threshold, fft, gat, part1   24.0      0.669648  0.458554   \n",
       "184      add_pool, fft, fold_0, gat, part1  799.0      0.613558  1.281941   \n",
       "7                      fft, gat, lr, part1  124.0      0.563487  0.416167   \n",
       "\n",
       "     val_accuracy  val_f1_class_1  val_f1_class_0  runtime_sec  total_epochs  \\\n",
       "25       0.876154        0.581818        0.927314  4408.092679          1000   \n",
       "11       0.870769        0.577889        0.923706  3794.153726          1000   \n",
       "4        0.853077        0.564920        0.911615  3772.087685          1000   \n",
       "14       0.851538        0.558352        0.910772  3837.919780          1000   \n",
       "187      0.859617        0.552283        0.916758  3492.618042          1000   \n",
       "190      0.863311        0.548092        0.919478  3447.972215          1000   \n",
       "149      0.869231        0.543011        0.923698  3576.004542          1000   \n",
       "53       0.842308        0.561028        0.903891  3918.134046          1000   \n",
       "171      0.848072        0.546207        0.908763  3138.975731          1000   \n",
       "47       0.846154        0.543379        0.907493  4423.609002          1000   \n",
       "1        0.846154        0.541284        0.907579  3757.224631          1000   \n",
       "36       0.850000        0.536817        0.910509  4157.100330          1000   \n",
       "173      0.843916        0.531856        0.906345  3136.333012          1000   \n",
       "40       0.844615        0.530233        0.906912  3912.552465          1000   \n",
       "174      0.858693        0.510400        0.917431  3240.204720          1000   \n",
       "44       0.843846        0.517815        0.906838  3922.090185          1000   \n",
       "191      0.850381        0.509091        0.911741  3464.081755          1000   \n",
       "18       0.850000        0.496124        0.911884  3897.993803          1000   \n",
       "32       0.844615        0.489899        0.908348  3706.688537          1000   \n",
       "22       0.842308        0.491315        0.906691  3641.053859          1000   \n",
       "182      0.845532        0.488923        0.909017  3209.740574          1000   \n",
       "189      0.841838        0.486122        0.906536  3162.557350          1000   \n",
       "168      0.804664        0.503521        0.878413  3146.851984          1000   \n",
       "178      0.852690        0.459322        0.914729  3351.342251          1000   \n",
       "186      0.857770        0.450000        0.918324  3170.529652          1000   \n",
       "50       0.816923        0.449074        0.890221  3454.775759          1000   \n",
       "184      0.840914        0.317146        0.909970  3186.814104          1000   \n",
       "7        0.835385        0.218978        0.907997  3784.745855          1000   \n",
       "\n",
       "     trainable_params  \n",
       "25             430000  \n",
       "11             198000  \n",
       "4              198000  \n",
       "14             198000  \n",
       "187            218000  \n",
       "190            218000  \n",
       "149            218000  \n",
       "53             198000  \n",
       "171            198000  \n",
       "47             198000  \n",
       "1              198000  \n",
       "36             298000  \n",
       "173            198000  \n",
       "40             198000  \n",
       "174            198000  \n",
       "44             198000  \n",
       "191            218000  \n",
       "18             199000  \n",
       "32              99500  \n",
       "22              95300  \n",
       "182            198000  \n",
       "189            198000  \n",
       "168            198000  \n",
       "178            198000  \n",
       "186            198000  \n",
       "50             198000  \n",
       "184            198000  \n",
       "7              198000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.part == \"part_1\") & (df[\"tags\"].str.contains(\"gat\"))].iloc[:,:12].sort_values(by=\"val_f1_macro\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6fbce8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_f1_macro</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1_class_1</th>\n",
       "      <th>val_f1_class_0</th>\n",
       "      <th>runtime_sec</th>\n",
       "      <th>total_epochs</th>\n",
       "      <th>trainable_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>pf6cdait</td>\n",
       "      <td>fast-river-314</td>\n",
       "      <td>fft, gcn, learned_pool, part1</td>\n",
       "      <td>699.0</td>\n",
       "      <td>0.800123</td>\n",
       "      <td>1.041971</td>\n",
       "      <td>0.889231</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.933579</td>\n",
       "      <td>3295.364610</td>\n",
       "      <td>1000</td>\n",
       "      <td>373000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>nks5mmpf</td>\n",
       "      <td>gallant-sun-322</td>\n",
       "      <td>fft, gcn, kaggle, learned_pool, part1, table1</td>\n",
       "      <td>699.0</td>\n",
       "      <td>0.800123</td>\n",
       "      <td>1.041971</td>\n",
       "      <td>0.889231</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.933579</td>\n",
       "      <td>3377.416183</td>\n",
       "      <td>1000</td>\n",
       "      <td>373000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>dp83oglc</td>\n",
       "      <td>sandy-smoke-349</td>\n",
       "      <td>fft, fold_2, gcn, learned_pool, part1</td>\n",
       "      <td>899.0</td>\n",
       "      <td>0.787842</td>\n",
       "      <td>1.074899</td>\n",
       "      <td>0.875317</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.924072</td>\n",
       "      <td>2682.039361</td>\n",
       "      <td>1000</td>\n",
       "      <td>373000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>s495lcgm</td>\n",
       "      <td>desert-shape-343</td>\n",
       "      <td>fft, fold_0, gcn, learned_pool, part1</td>\n",
       "      <td>749.0</td>\n",
       "      <td>0.785672</td>\n",
       "      <td>1.016277</td>\n",
       "      <td>0.875317</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.924285</td>\n",
       "      <td>3319.402295</td>\n",
       "      <td>1000</td>\n",
       "      <td>373000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>wdixxj66</td>\n",
       "      <td>lunar-bee-313</td>\n",
       "      <td>fft, gcn, gcn_0_5_dist, learned_pool, part1</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.783209</td>\n",
       "      <td>0.791914</td>\n",
       "      <td>0.873077</td>\n",
       "      <td>0.643629</td>\n",
       "      <td>0.922789</td>\n",
       "      <td>2936.468164</td>\n",
       "      <td>1000</td>\n",
       "      <td>373000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>wvey8vf0</td>\n",
       "      <td>treasured-bee-347</td>\n",
       "      <td>fft, fold_1, gcn, learned_pool, part1</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0.777667</td>\n",
       "      <td>0.385703</td>\n",
       "      <td>0.873470</td>\n",
       "      <td>0.631720</td>\n",
       "      <td>0.923613</td>\n",
       "      <td>3090.034522</td>\n",
       "      <td>1000</td>\n",
       "      <td>373000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>anjw34ub</td>\n",
       "      <td>scarlet-resonance-159</td>\n",
       "      <td>fft, gcn_0_5_dist, hidden_dim, part1</td>\n",
       "      <td>949.0</td>\n",
       "      <td>0.774556</td>\n",
       "      <td>0.376829</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>2683.286364</td>\n",
       "      <td>1000</td>\n",
       "      <td>62100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>33lcxzg1</td>\n",
       "      <td>lilac-haze-164</td>\n",
       "      <td>fft, gcn_0_5_dist, part1, pooling</td>\n",
       "      <td>774.0</td>\n",
       "      <td>0.759586</td>\n",
       "      <td>0.371426</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.596659</td>\n",
       "      <td>0.922513</td>\n",
       "      <td>2667.857341</td>\n",
       "      <td>1000</td>\n",
       "      <td>26900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>j1m6bnz5</td>\n",
       "      <td>iconic-paper-345</td>\n",
       "      <td>fft, fold_1, gcn, max_pool, part1</td>\n",
       "      <td>799.0</td>\n",
       "      <td>0.759229</td>\n",
       "      <td>0.350843</td>\n",
       "      <td>0.860079</td>\n",
       "      <td>0.603403</td>\n",
       "      <td>0.915055</td>\n",
       "      <td>3012.771081</td>\n",
       "      <td>1000</td>\n",
       "      <td>62100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0cubreec</td>\n",
       "      <td>still-wildflower-127</td>\n",
       "      <td>fft, gcn, part1, weighted_sampler</td>\n",
       "      <td>874.0</td>\n",
       "      <td>0.756934</td>\n",
       "      <td>0.378826</td>\n",
       "      <td>0.846923</td>\n",
       "      <td>0.609037</td>\n",
       "      <td>0.904830</td>\n",
       "      <td>3314.047066</td>\n",
       "      <td>1000</td>\n",
       "      <td>26900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>bcrkrxlx</td>\n",
       "      <td>giddy-vortex-152</td>\n",
       "      <td>fft, gcn_0_5_dist, part1, wd</td>\n",
       "      <td>924.0</td>\n",
       "      <td>0.755796</td>\n",
       "      <td>0.361493</td>\n",
       "      <td>0.870769</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.923358</td>\n",
       "      <td>2618.029310</td>\n",
       "      <td>1000</td>\n",
       "      <td>26900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8z0ee6vj</td>\n",
       "      <td>astral-river-124</td>\n",
       "      <td>distance_threshold, fft, gcn, part1</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.753884</td>\n",
       "      <td>0.376195</td>\n",
       "      <td>0.868462</td>\n",
       "      <td>0.585956</td>\n",
       "      <td>0.921811</td>\n",
       "      <td>3109.777618</td>\n",
       "      <td>1000</td>\n",
       "      <td>26900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>4u0x4gsg</td>\n",
       "      <td>sage-bush-334</td>\n",
       "      <td>baseline, fft, fold_2, gcn, part1</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.751793</td>\n",
       "      <td>0.396919</td>\n",
       "      <td>0.855461</td>\n",
       "      <td>0.591384</td>\n",
       "      <td>0.912202</td>\n",
       "      <td>2955.300879</td>\n",
       "      <td>1000</td>\n",
       "      <td>62100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>i3gor2eg</td>\n",
       "      <td>super-leaf-330</td>\n",
       "      <td>baseline, fft, fold_1, gcn, part1</td>\n",
       "      <td>899.0</td>\n",
       "      <td>0.751166</td>\n",
       "      <td>0.349253</td>\n",
       "      <td>0.872316</td>\n",
       "      <td>0.577540</td>\n",
       "      <td>0.924793</td>\n",
       "      <td>2954.689860</td>\n",
       "      <td>1000</td>\n",
       "      <td>62100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>v8as8jcy</td>\n",
       "      <td>chocolate-oath-107</td>\n",
       "      <td>fft, gcn, part1, pooling</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.750121</td>\n",
       "      <td>0.369401</td>\n",
       "      <td>0.858462</td>\n",
       "      <td>0.585586</td>\n",
       "      <td>0.914657</td>\n",
       "      <td>3286.664522</td>\n",
       "      <td>1000</td>\n",
       "      <td>26900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>en9u52u3</td>\n",
       "      <td>chocolate-smoke-355</td>\n",
       "      <td>add_pool, fft, fold_1, gcn, part1</td>\n",
       "      <td>974.0</td>\n",
       "      <td>0.747864</td>\n",
       "      <td>0.356956</td>\n",
       "      <td>0.861926</td>\n",
       "      <td>0.578279</td>\n",
       "      <td>0.917449</td>\n",
       "      <td>3010.104028</td>\n",
       "      <td>1000</td>\n",
       "      <td>62100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8or3azbp</td>\n",
       "      <td>wandering-smoke-104</td>\n",
       "      <td>fft, gcn, hidden_dim, part1</td>\n",
       "      <td>899.0</td>\n",
       "      <td>0.747406</td>\n",
       "      <td>0.367370</td>\n",
       "      <td>0.857692</td>\n",
       "      <td>0.580499</td>\n",
       "      <td>0.914312</td>\n",
       "      <td>3458.181803</td>\n",
       "      <td>1000</td>\n",
       "      <td>62100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>4bfqtqy1</td>\n",
       "      <td>swept-fire-358</td>\n",
       "      <td>add_pool, fft, fold_2, gcn, part1</td>\n",
       "      <td>899.0</td>\n",
       "      <td>0.747167</td>\n",
       "      <td>0.369307</td>\n",
       "      <td>0.849919</td>\n",
       "      <td>0.585987</td>\n",
       "      <td>0.908347</td>\n",
       "      <td>3028.041183</td>\n",
       "      <td>1000</td>\n",
       "      <td>62100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yqswshy4</td>\n",
       "      <td>different-plasma-83</td>\n",
       "      <td>baseline, fft, gcn, part1</td>\n",
       "      <td>899.0</td>\n",
       "      <td>0.744443</td>\n",
       "      <td>0.357107</td>\n",
       "      <td>0.870769</td>\n",
       "      <td>0.564767</td>\n",
       "      <td>0.924119</td>\n",
       "      <td>3235.693559</td>\n",
       "      <td>1000</td>\n",
       "      <td>26900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>867echov</td>\n",
       "      <td>blooming-star-348</td>\n",
       "      <td>fft, fold_2, gcn, max_pool, part1</td>\n",
       "      <td>799.0</td>\n",
       "      <td>0.743595</td>\n",
       "      <td>0.378134</td>\n",
       "      <td>0.850381</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.909065</td>\n",
       "      <td>3009.112561</td>\n",
       "      <td>1000</td>\n",
       "      <td>62100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>74j0wn5o</td>\n",
       "      <td>misunderstood-sky-327</td>\n",
       "      <td>baseline, fft, fold_0, gcn, part1</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.742226</td>\n",
       "      <td>0.386867</td>\n",
       "      <td>0.862387</td>\n",
       "      <td>0.566230</td>\n",
       "      <td>0.918222</td>\n",
       "      <td>2956.275832</td>\n",
       "      <td>1000</td>\n",
       "      <td>62100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>mleo8cgm</td>\n",
       "      <td>pious-salad-351</td>\n",
       "      <td>add_pool, fft, fold_0, gcn, part1</td>\n",
       "      <td>974.0</td>\n",
       "      <td>0.738439</td>\n",
       "      <td>0.385697</td>\n",
       "      <td>0.851305</td>\n",
       "      <td>0.566622</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>3001.625929</td>\n",
       "      <td>1000</td>\n",
       "      <td>62100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vss3wvfs</td>\n",
       "      <td>usual-surf-86</td>\n",
       "      <td>fft, gcn, lr, part1</td>\n",
       "      <td>924.0</td>\n",
       "      <td>0.738353</td>\n",
       "      <td>0.361807</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.917883</td>\n",
       "      <td>3216.958506</td>\n",
       "      <td>1000</td>\n",
       "      <td>26900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>zttysj21</td>\n",
       "      <td>winter-flower-342</td>\n",
       "      <td>fft, fold_0, gcn, max_pool, part1</td>\n",
       "      <td>824.0</td>\n",
       "      <td>0.737587</td>\n",
       "      <td>0.388963</td>\n",
       "      <td>0.857770</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.915175</td>\n",
       "      <td>3000.829366</td>\n",
       "      <td>1000</td>\n",
       "      <td>62100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>mt3wbyli</td>\n",
       "      <td>sandy-salad-154</td>\n",
       "      <td>fft, gcn_0_5_dist, part1, wd</td>\n",
       "      <td>849.0</td>\n",
       "      <td>0.733767</td>\n",
       "      <td>0.367714</td>\n",
       "      <td>0.863077</td>\n",
       "      <td>0.548223</td>\n",
       "      <td>0.919311</td>\n",
       "      <td>2625.969546</td>\n",
       "      <td>1000</td>\n",
       "      <td>26900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8vc5ot3j</td>\n",
       "      <td>devout-wind-92</td>\n",
       "      <td>fft, gcn, part1, wd</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.733413</td>\n",
       "      <td>0.354882</td>\n",
       "      <td>0.864615</td>\n",
       "      <td>0.546392</td>\n",
       "      <td>0.920434</td>\n",
       "      <td>3233.989342</td>\n",
       "      <td>1000</td>\n",
       "      <td>26900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>vhj5lr51</td>\n",
       "      <td>easy-water-166</td>\n",
       "      <td>fft, gcn_0_5_dist, part1, weighted_sampler</td>\n",
       "      <td>699.0</td>\n",
       "      <td>0.727355</td>\n",
       "      <td>0.406011</td>\n",
       "      <td>0.837692</td>\n",
       "      <td>0.553911</td>\n",
       "      <td>0.900799</td>\n",
       "      <td>2684.280360</td>\n",
       "      <td>1000</td>\n",
       "      <td>26900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5uuit4t4</td>\n",
       "      <td>earnest-universe-157</td>\n",
       "      <td>fft, gcn_0_5_dist, hidden_dim, part1</td>\n",
       "      <td>874.0</td>\n",
       "      <td>0.726339</td>\n",
       "      <td>0.374715</td>\n",
       "      <td>0.852308</td>\n",
       "      <td>0.540670</td>\n",
       "      <td>0.912007</td>\n",
       "      <td>2612.293193</td>\n",
       "      <td>1000</td>\n",
       "      <td>12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9yhoaavq</td>\n",
       "      <td>fragrant-hill-119</td>\n",
       "      <td>distance_threshold, fft, gcn, part1</td>\n",
       "      <td>849.0</td>\n",
       "      <td>0.725677</td>\n",
       "      <td>0.388203</td>\n",
       "      <td>0.844615</td>\n",
       "      <td>0.545045</td>\n",
       "      <td>0.906308</td>\n",
       "      <td>3473.326559</td>\n",
       "      <td>1000</td>\n",
       "      <td>26900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2azoy3sl</td>\n",
       "      <td>distinctive-wave-102</td>\n",
       "      <td>fft, gcn, hidden_dim, part1</td>\n",
       "      <td>974.0</td>\n",
       "      <td>0.725014</td>\n",
       "      <td>0.381092</td>\n",
       "      <td>0.857692</td>\n",
       "      <td>0.534005</td>\n",
       "      <td>0.916024</td>\n",
       "      <td>3168.279046</td>\n",
       "      <td>1000</td>\n",
       "      <td>12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>n3e4ifwc</td>\n",
       "      <td>dauntless-energy-163</td>\n",
       "      <td>fft, gcn_0_5_dist, part1, pooling</td>\n",
       "      <td>499.0</td>\n",
       "      <td>0.724703</td>\n",
       "      <td>0.422680</td>\n",
       "      <td>0.836923</td>\n",
       "      <td>0.548936</td>\n",
       "      <td>0.900469</td>\n",
       "      <td>2648.038195</td>\n",
       "      <td>1000</td>\n",
       "      <td>26900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1dzhqmrt</td>\n",
       "      <td>gentle-shape-115</td>\n",
       "      <td>fft, gcn, part1, pooling</td>\n",
       "      <td>949.0</td>\n",
       "      <td>0.722719</td>\n",
       "      <td>0.349210</td>\n",
       "      <td>0.857692</td>\n",
       "      <td>0.529262</td>\n",
       "      <td>0.916176</td>\n",
       "      <td>3330.780033</td>\n",
       "      <td>1000</td>\n",
       "      <td>26900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>fbn55cyi</td>\n",
       "      <td>absurd-sea-150</td>\n",
       "      <td>fft, gcn_0_5_dist, lr, part1</td>\n",
       "      <td>774.0</td>\n",
       "      <td>0.720636</td>\n",
       "      <td>0.375785</td>\n",
       "      <td>0.856923</td>\n",
       "      <td>0.525510</td>\n",
       "      <td>0.915761</td>\n",
       "      <td>2571.205796</td>\n",
       "      <td>1000</td>\n",
       "      <td>26900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>u4ikyulb</td>\n",
       "      <td>hearty-spaceship-99</td>\n",
       "      <td>batchnorm, fft, gcn, part1</td>\n",
       "      <td>799.0</td>\n",
       "      <td>0.716983</td>\n",
       "      <td>1.534367</td>\n",
       "      <td>0.837692</td>\n",
       "      <td>0.532151</td>\n",
       "      <td>0.901815</td>\n",
       "      <td>3274.723125</td>\n",
       "      <td>1000</td>\n",
       "      <td>27200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3ifjf93g</td>\n",
       "      <td>proud-paper-95</td>\n",
       "      <td>fft, gcn, part1, wd</td>\n",
       "      <td>849.0</td>\n",
       "      <td>0.715786</td>\n",
       "      <td>0.413550</td>\n",
       "      <td>0.843077</td>\n",
       "      <td>0.525581</td>\n",
       "      <td>0.905991</td>\n",
       "      <td>3239.993909</td>\n",
       "      <td>1000</td>\n",
       "      <td>26900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>pyocw8kv</td>\n",
       "      <td>restful-universe-155</td>\n",
       "      <td>batchnorm, fft, gcn_0_5_dist, part1</td>\n",
       "      <td>424.0</td>\n",
       "      <td>0.698528</td>\n",
       "      <td>1.605605</td>\n",
       "      <td>0.822308</td>\n",
       "      <td>0.505353</td>\n",
       "      <td>0.891702</td>\n",
       "      <td>2633.895699</td>\n",
       "      <td>1000</td>\n",
       "      <td>27200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>clqy249w</td>\n",
       "      <td>atomic-pyramid-89</td>\n",
       "      <td>fft, gcn, lr, part1</td>\n",
       "      <td>774.0</td>\n",
       "      <td>0.674154</td>\n",
       "      <td>0.397784</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.913526</td>\n",
       "      <td>3217.067505</td>\n",
       "      <td>1000</td>\n",
       "      <td>26900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>gvzejyfo</td>\n",
       "      <td>peach-silence-151</td>\n",
       "      <td>fft, gcn_0_5_dist, lr, part1</td>\n",
       "      <td>874.0</td>\n",
       "      <td>0.673285</td>\n",
       "      <td>0.400120</td>\n",
       "      <td>0.849231</td>\n",
       "      <td>0.433526</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>2606.065611</td>\n",
       "      <td>1000</td>\n",
       "      <td>26900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       run_id               run_name  \\\n",
       "148  pf6cdait         fast-river-314   \n",
       "154  nks5mmpf        gallant-sun-322   \n",
       "181  dp83oglc        sandy-smoke-349   \n",
       "175  s495lcgm       desert-shape-343   \n",
       "147  wdixxj66          lunar-bee-313   \n",
       "179  wvey8vf0      treasured-bee-347   \n",
       "68   anjw34ub  scarlet-resonance-159   \n",
       "73   33lcxzg1         lilac-haze-164   \n",
       "177  j1m6bnz5       iconic-paper-345   \n",
       "41   0cubreec   still-wildflower-127   \n",
       "61   bcrkrxlx       giddy-vortex-152   \n",
       "38   8z0ee6vj       astral-river-124   \n",
       "166  4u0x4gsg          sage-bush-334   \n",
       "162  i3gor2eg         super-leaf-330   \n",
       "24   v8as8jcy     chocolate-oath-107   \n",
       "185  en9u52u3    chocolate-smoke-355   \n",
       "21   8or3azbp    wandering-smoke-104   \n",
       "188  4bfqtqy1         swept-fire-358   \n",
       "0    yqswshy4    different-plasma-83   \n",
       "180  867echov      blooming-star-348   \n",
       "159  74j0wn5o  misunderstood-sky-327   \n",
       "183  mleo8cgm        pious-salad-351   \n",
       "3    vss3wvfs          usual-surf-86   \n",
       "176  zttysj21      winter-flower-342   \n",
       "63   mt3wbyli        sandy-salad-154   \n",
       "9    8vc5ot3j         devout-wind-92   \n",
       "75   vhj5lr51         easy-water-166   \n",
       "66   5uuit4t4   earnest-universe-157   \n",
       "33   9yhoaavq      fragrant-hill-119   \n",
       "19   2azoy3sl   distinctive-wave-102   \n",
       "72   n3e4ifwc   dauntless-energy-163   \n",
       "29   1dzhqmrt       gentle-shape-115   \n",
       "59   fbn55cyi         absurd-sea-150   \n",
       "16   u4ikyulb    hearty-spaceship-99   \n",
       "12   3ifjf93g         proud-paper-95   \n",
       "64   pyocw8kv   restful-universe-155   \n",
       "6    clqy249w      atomic-pyramid-89   \n",
       "60   gvzejyfo      peach-silence-151   \n",
       "\n",
       "                                              tags  epoch  val_f1_macro  \\\n",
       "148                  fft, gcn, learned_pool, part1  699.0      0.800123   \n",
       "154  fft, gcn, kaggle, learned_pool, part1, table1  699.0      0.800123   \n",
       "181          fft, fold_2, gcn, learned_pool, part1  899.0      0.787842   \n",
       "175          fft, fold_0, gcn, learned_pool, part1  749.0      0.785672   \n",
       "147    fft, gcn, gcn_0_5_dist, learned_pool, part1  174.0      0.783209   \n",
       "179          fft, fold_1, gcn, learned_pool, part1  324.0      0.777667   \n",
       "68            fft, gcn_0_5_dist, hidden_dim, part1  949.0      0.774556   \n",
       "73               fft, gcn_0_5_dist, part1, pooling  774.0      0.759586   \n",
       "177              fft, fold_1, gcn, max_pool, part1  799.0      0.759229   \n",
       "41               fft, gcn, part1, weighted_sampler  874.0      0.756934   \n",
       "61                    fft, gcn_0_5_dist, part1, wd  924.0      0.755796   \n",
       "38             distance_threshold, fft, gcn, part1  999.0      0.753884   \n",
       "166              baseline, fft, fold_2, gcn, part1  999.0      0.751793   \n",
       "162              baseline, fft, fold_1, gcn, part1  899.0      0.751166   \n",
       "24                        fft, gcn, part1, pooling  999.0      0.750121   \n",
       "185              add_pool, fft, fold_1, gcn, part1  974.0      0.747864   \n",
       "21                     fft, gcn, hidden_dim, part1  899.0      0.747406   \n",
       "188              add_pool, fft, fold_2, gcn, part1  899.0      0.747167   \n",
       "0                        baseline, fft, gcn, part1  899.0      0.744443   \n",
       "180              fft, fold_2, gcn, max_pool, part1  799.0      0.743595   \n",
       "159              baseline, fft, fold_0, gcn, part1  999.0      0.742226   \n",
       "183              add_pool, fft, fold_0, gcn, part1  974.0      0.738439   \n",
       "3                              fft, gcn, lr, part1  924.0      0.738353   \n",
       "176              fft, fold_0, gcn, max_pool, part1  824.0      0.737587   \n",
       "63                    fft, gcn_0_5_dist, part1, wd  849.0      0.733767   \n",
       "9                              fft, gcn, part1, wd  999.0      0.733413   \n",
       "75      fft, gcn_0_5_dist, part1, weighted_sampler  699.0      0.727355   \n",
       "66            fft, gcn_0_5_dist, hidden_dim, part1  874.0      0.726339   \n",
       "33             distance_threshold, fft, gcn, part1  849.0      0.725677   \n",
       "19                     fft, gcn, hidden_dim, part1  974.0      0.725014   \n",
       "72               fft, gcn_0_5_dist, part1, pooling  499.0      0.724703   \n",
       "29                        fft, gcn, part1, pooling  949.0      0.722719   \n",
       "59                    fft, gcn_0_5_dist, lr, part1  774.0      0.720636   \n",
       "16                      batchnorm, fft, gcn, part1  799.0      0.716983   \n",
       "12                             fft, gcn, part1, wd  849.0      0.715786   \n",
       "64             batchnorm, fft, gcn_0_5_dist, part1  424.0      0.698528   \n",
       "6                              fft, gcn, lr, part1  774.0      0.674154   \n",
       "60                    fft, gcn_0_5_dist, lr, part1  874.0      0.673285   \n",
       "\n",
       "     val_loss  val_accuracy  val_f1_class_1  val_f1_class_0  runtime_sec  \\\n",
       "148  1.041971      0.889231        0.666667        0.933579  3295.364610   \n",
       "154  1.041971      0.889231        0.666667        0.933579  3377.416183   \n",
       "181  1.074899      0.875317        0.651613        0.924072  2682.039361   \n",
       "175  1.016277      0.875317        0.647059        0.924285  3319.402295   \n",
       "147  0.791914      0.873077        0.643629        0.922789  2936.468164   \n",
       "179  0.385703      0.873470        0.631720        0.923613  3090.034522   \n",
       "68   0.376829      0.876923        0.622642        0.926471  2683.286364   \n",
       "73   0.371426      0.870000        0.596659        0.922513  2667.857341   \n",
       "177  0.350843      0.860079        0.603403        0.915055  3012.771081   \n",
       "41   0.378826      0.846923        0.609037        0.904830  3314.047066   \n",
       "61   0.361493      0.870769        0.588235        0.923358  2618.029310   \n",
       "38   0.376195      0.868462        0.585956        0.921811  3109.777618   \n",
       "166  0.396919      0.855461        0.591384        0.912202  2955.300879   \n",
       "162  0.349253      0.872316        0.577540        0.924793  2954.689860   \n",
       "24   0.369401      0.858462        0.585586        0.914657  3286.664522   \n",
       "185  0.356956      0.861926        0.578279        0.917449  3010.104028   \n",
       "21   0.367370      0.857692        0.580499        0.914312  3458.181803   \n",
       "188  0.369307      0.849919        0.585987        0.908347  3028.041183   \n",
       "0    0.357107      0.870769        0.564767        0.924119  3235.693559   \n",
       "180  0.378134      0.850381        0.578125        0.909065  3009.112561   \n",
       "159  0.386867      0.862387        0.566230        0.918222  2956.275832   \n",
       "183  0.385697      0.851305        0.566622        0.910256  3001.625929   \n",
       "3    0.361807      0.861538        0.558824        0.917883  3216.958506   \n",
       "176  0.388963      0.857770        0.560000        0.915175  3000.829366   \n",
       "63   0.367714      0.863077        0.548223        0.919311  2625.969546   \n",
       "9    0.354882      0.864615        0.546392        0.920434  3233.989342   \n",
       "75   0.406011      0.837692        0.553911        0.900799  2684.280360   \n",
       "66   0.374715      0.852308        0.540670        0.912007  2612.293193   \n",
       "33   0.388203      0.844615        0.545045        0.906308  3473.326559   \n",
       "19   0.381092      0.857692        0.534005        0.916024  3168.279046   \n",
       "72   0.422680      0.836923        0.548936        0.900469  2648.038195   \n",
       "29   0.349210      0.857692        0.529262        0.916176  3330.780033   \n",
       "59   0.375785      0.856923        0.525510        0.915761  2571.205796   \n",
       "16   1.534367      0.837692        0.532151        0.901815  3274.723125   \n",
       "12   0.413550      0.843077        0.525581        0.905991  3239.993909   \n",
       "64   1.605605      0.822308        0.505353        0.891702  2633.895699   \n",
       "6    0.397784      0.850000        0.434783        0.913526  3217.067505   \n",
       "60   0.400120      0.849231        0.433526        0.913043  2606.065611   \n",
       "\n",
       "     total_epochs  trainable_params  \n",
       "148          1000            373000  \n",
       "154          1000            373000  \n",
       "181          1000            373000  \n",
       "175          1000            373000  \n",
       "147          1000            373000  \n",
       "179          1000            373000  \n",
       "68           1000             62100  \n",
       "73           1000             26900  \n",
       "177          1000             62100  \n",
       "41           1000             26900  \n",
       "61           1000             26900  \n",
       "38           1000             26900  \n",
       "166          1000             62100  \n",
       "162          1000             62100  \n",
       "24           1000             26900  \n",
       "185          1000             62100  \n",
       "21           1000             62100  \n",
       "188          1000             62100  \n",
       "0            1000             26900  \n",
       "180          1000             62100  \n",
       "159          1000             62100  \n",
       "183          1000             62100  \n",
       "3            1000             26900  \n",
       "176          1000             62100  \n",
       "63           1000             26900  \n",
       "9            1000             26900  \n",
       "75           1000             26900  \n",
       "66           1000             12400  \n",
       "33           1000             26900  \n",
       "19           1000             12400  \n",
       "72           1000             26900  \n",
       "29           1000             26900  \n",
       "59           1000             26900  \n",
       "16           1000             27200  \n",
       "12           1000             26900  \n",
       "64           1000             27200  \n",
       "6            1000             26900  \n",
       "60           1000             26900  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.part == \"part_1\") & (df[\"tags\"].str.contains(\"gcn\"))].iloc[:,:12].sort_values(by=\"val_f1_macro\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ecc330",
   "metadata": {},
   "source": [
    "## Part 2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cb7479f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_f1_macro</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1_class_1</th>\n",
       "      <th>val_f1_class_0</th>\n",
       "      <th>runtime_sec</th>\n",
       "      <th>total_epochs</th>\n",
       "      <th>trainable_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>3pz4rcp5</td>\n",
       "      <td>frosty-oath-175</td>\n",
       "      <td>dct_downsample, kaggle, lstm, part2a</td>\n",
       "      <td>849.0</td>\n",
       "      <td>0.809426</td>\n",
       "      <td>0.937859</td>\n",
       "      <td>0.886923</td>\n",
       "      <td>0.687898</td>\n",
       "      <td>0.930954</td>\n",
       "      <td>2440.230735</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ai7jideq</td>\n",
       "      <td>azure-valley-187</td>\n",
       "      <td>lstm, part2a, wavelet</td>\n",
       "      <td>974.0</td>\n",
       "      <td>0.802133</td>\n",
       "      <td>0.663091</td>\n",
       "      <td>0.886923</td>\n",
       "      <td>0.672606</td>\n",
       "      <td>0.931660</td>\n",
       "      <td>1252.736297</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>515jflw9</td>\n",
       "      <td>olive-elevator-168</td>\n",
       "      <td>lstm, part2a, window_downsample</td>\n",
       "      <td>924.0</td>\n",
       "      <td>0.795562</td>\n",
       "      <td>1.120305</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.660634</td>\n",
       "      <td>0.930491</td>\n",
       "      <td>1323.405299</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>27s17eqd</td>\n",
       "      <td>robust-wave-173</td>\n",
       "      <td>dct_downsample, lstm, part2a</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.790036</td>\n",
       "      <td>0.369083</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.934911</td>\n",
       "      <td>3062.517461</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>s1j72ggx</td>\n",
       "      <td>deep-resonance-170</td>\n",
       "      <td>lstm, part2a, window_downsample</td>\n",
       "      <td>949.0</td>\n",
       "      <td>0.782128</td>\n",
       "      <td>1.151947</td>\n",
       "      <td>0.874615</td>\n",
       "      <td>0.640177</td>\n",
       "      <td>0.924080</td>\n",
       "      <td>866.376918</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>u4isd9og</td>\n",
       "      <td>prime-lion-169</td>\n",
       "      <td>lstm, part2a, window_downsample</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.781933</td>\n",
       "      <td>0.425083</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.638009</td>\n",
       "      <td>0.925857</td>\n",
       "      <td>1011.316697</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>35cumlml</td>\n",
       "      <td>rosy-energy-167</td>\n",
       "      <td>lstm, part2a, window_downsample</td>\n",
       "      <td>824.0</td>\n",
       "      <td>0.780858</td>\n",
       "      <td>0.836489</td>\n",
       "      <td>0.879231</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.927683</td>\n",
       "      <td>1437.813789</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ejgxtio2</td>\n",
       "      <td>morning-wind-188</td>\n",
       "      <td>lstm, part2a, wavelet</td>\n",
       "      <td>499.0</td>\n",
       "      <td>0.780409</td>\n",
       "      <td>0.898344</td>\n",
       "      <td>0.873846</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>0.923650</td>\n",
       "      <td>1033.490723</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>hxwwgwia</td>\n",
       "      <td>lucky-wave-161</td>\n",
       "      <td>decimate, lstm, part2a</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.775522</td>\n",
       "      <td>0.501352</td>\n",
       "      <td>0.873077</td>\n",
       "      <td>0.627540</td>\n",
       "      <td>0.923505</td>\n",
       "      <td>942.991109</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>mdhyymey</td>\n",
       "      <td>balmy-grass-185</td>\n",
       "      <td>lstm, part2a, wavelet</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.774264</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.870769</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.921860</td>\n",
       "      <td>1706.394955</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>8r197hnq</td>\n",
       "      <td>wise-universe-176</td>\n",
       "      <td>dct_downsample, lstm, part2a</td>\n",
       "      <td>574.0</td>\n",
       "      <td>0.772520</td>\n",
       "      <td>0.869224</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.623608</td>\n",
       "      <td>0.921432</td>\n",
       "      <td>2007.406228</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>all7n19v</td>\n",
       "      <td>morning-plasma-160</td>\n",
       "      <td>decimate, lstm, part2a</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.770080</td>\n",
       "      <td>1.014607</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.618510</td>\n",
       "      <td>0.921650</td>\n",
       "      <td>1180.309417</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>kbawygcw</td>\n",
       "      <td>absurd-lion-158</td>\n",
       "      <td>decimate, lstm, part2a</td>\n",
       "      <td>899.0</td>\n",
       "      <td>0.768826</td>\n",
       "      <td>0.910972</td>\n",
       "      <td>0.873077</td>\n",
       "      <td>0.613583</td>\n",
       "      <td>0.924068</td>\n",
       "      <td>1423.331413</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>byfvm0hv</td>\n",
       "      <td>tough-smoke-171</td>\n",
       "      <td>dct_downsample, lstm, part2a</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.367491</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>4947.597631</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>zozf6lw9</td>\n",
       "      <td>graceful-dream-165</td>\n",
       "      <td>lstm, part2a, window_downsample</td>\n",
       "      <td>799.0</td>\n",
       "      <td>0.763514</td>\n",
       "      <td>0.947596</td>\n",
       "      <td>0.864615</td>\n",
       "      <td>0.608889</td>\n",
       "      <td>0.918140</td>\n",
       "      <td>2169.700055</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>fgp3sdow</td>\n",
       "      <td>logical-field-156</td>\n",
       "      <td>decimate, lstm, part2a</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.757696</td>\n",
       "      <td>1.133394</td>\n",
       "      <td>0.869231</td>\n",
       "      <td>0.593301</td>\n",
       "      <td>0.922090</td>\n",
       "      <td>2170.002377</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>73d6qi89</td>\n",
       "      <td>ethereal-snow-182</td>\n",
       "      <td>lstm, part2a, wavelet</td>\n",
       "      <td>549.0</td>\n",
       "      <td>0.745408</td>\n",
       "      <td>1.105789</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.573460</td>\n",
       "      <td>0.917355</td>\n",
       "      <td>2666.657123</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>j4500fkg</td>\n",
       "      <td>sandy-leaf-179</td>\n",
       "      <td>lstm, part2a, wavelet</td>\n",
       "      <td>549.0</td>\n",
       "      <td>0.737648</td>\n",
       "      <td>0.959075</td>\n",
       "      <td>0.846923</td>\n",
       "      <td>0.568330</td>\n",
       "      <td>0.906966</td>\n",
       "      <td>4478.096315</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>lsk6ln47</td>\n",
       "      <td>glowing-terrain-162</td>\n",
       "      <td>lstm, part2a, window_downsample</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.731502</td>\n",
       "      <td>1.110921</td>\n",
       "      <td>0.852308</td>\n",
       "      <td>0.551402</td>\n",
       "      <td>0.911602</td>\n",
       "      <td>4415.639785</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>vgpeqi6l</td>\n",
       "      <td>fresh-plasma-153</td>\n",
       "      <td>decimate, lstm, part2a</td>\n",
       "      <td>949.0</td>\n",
       "      <td>0.724276</td>\n",
       "      <td>1.306046</td>\n",
       "      <td>0.840769</td>\n",
       "      <td>0.545055</td>\n",
       "      <td>0.903497</td>\n",
       "      <td>4373.975848</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>7n0bx3nl</td>\n",
       "      <td>expert-glade-149</td>\n",
       "      <td>decimate, lstm, part2a</td>\n",
       "      <td>874.0</td>\n",
       "      <td>0.707514</td>\n",
       "      <td>1.094051</td>\n",
       "      <td>0.841538</td>\n",
       "      <td>0.509524</td>\n",
       "      <td>0.905505</td>\n",
       "      <td>7947.329873</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>p2lzfzn7</td>\n",
       "      <td>wandering-pyramid-178</td>\n",
       "      <td>dct_downsample, lstm, part2a</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.700652</td>\n",
       "      <td>1.356591</td>\n",
       "      <td>0.829231</td>\n",
       "      <td>0.504464</td>\n",
       "      <td>0.896840</td>\n",
       "      <td>1923.672788</td>\n",
       "      <td>1000</td>\n",
       "      <td>88400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      run_id               run_name                                  tags  \\\n",
       "83  3pz4rcp5        frosty-oath-175  dct_downsample, kaggle, lstm, part2a   \n",
       "95  ai7jideq       azure-valley-187                 lstm, part2a, wavelet   \n",
       "77  515jflw9     olive-elevator-168       lstm, part2a, window_downsample   \n",
       "81  27s17eqd        robust-wave-173          dct_downsample, lstm, part2a   \n",
       "79  s1j72ggx     deep-resonance-170       lstm, part2a, window_downsample   \n",
       "78  u4isd9og         prime-lion-169       lstm, part2a, window_downsample   \n",
       "76  35cumlml        rosy-energy-167       lstm, part2a, window_downsample   \n",
       "96  ejgxtio2       morning-wind-188                 lstm, part2a, wavelet   \n",
       "70  hxwwgwia         lucky-wave-161                decimate, lstm, part2a   \n",
       "93  mdhyymey        balmy-grass-185                 lstm, part2a, wavelet   \n",
       "84  8r197hnq      wise-universe-176          dct_downsample, lstm, part2a   \n",
       "69  all7n19v     morning-plasma-160                decimate, lstm, part2a   \n",
       "67  kbawygcw        absurd-lion-158                decimate, lstm, part2a   \n",
       "80  byfvm0hv        tough-smoke-171          dct_downsample, lstm, part2a   \n",
       "74  zozf6lw9     graceful-dream-165       lstm, part2a, window_downsample   \n",
       "65  fgp3sdow      logical-field-156                decimate, lstm, part2a   \n",
       "90  73d6qi89      ethereal-snow-182                 lstm, part2a, wavelet   \n",
       "87  j4500fkg         sandy-leaf-179                 lstm, part2a, wavelet   \n",
       "71  lsk6ln47    glowing-terrain-162       lstm, part2a, window_downsample   \n",
       "62  vgpeqi6l       fresh-plasma-153                decimate, lstm, part2a   \n",
       "58  7n0bx3nl       expert-glade-149                decimate, lstm, part2a   \n",
       "86  p2lzfzn7  wandering-pyramid-178          dct_downsample, lstm, part2a   \n",
       "\n",
       "    epoch  val_f1_macro  val_loss  val_accuracy  val_f1_class_1  \\\n",
       "83  849.0      0.809426  0.937859      0.886923        0.687898   \n",
       "95  974.0      0.802133  0.663091      0.886923        0.672606   \n",
       "77  924.0      0.795562  1.120305      0.884615        0.660634   \n",
       "81   99.0      0.790036  0.369083      0.890000        0.645161   \n",
       "79  949.0      0.782128  1.151947      0.874615        0.640177   \n",
       "78   74.0      0.781933  0.425083      0.876923        0.638009   \n",
       "76  824.0      0.780858  0.836489      0.879231        0.634033   \n",
       "96  499.0      0.780409  0.898344      0.873846        0.637168   \n",
       "70   99.0      0.775522  0.501352      0.873077        0.627540   \n",
       "93  999.0      0.774264  0.764460      0.870769        0.626667   \n",
       "84  574.0      0.772520  0.869224      0.870000        0.623608   \n",
       "69  999.0      0.770080  1.014607      0.870000        0.618510   \n",
       "67  899.0      0.768826  0.910972      0.873077        0.613583   \n",
       "80   74.0      0.763636  0.367491      0.876923        0.600000   \n",
       "74  799.0      0.763514  0.947596      0.864615        0.608889   \n",
       "65  999.0      0.757696  1.133394      0.869231        0.593301   \n",
       "90  549.0      0.745408  1.105789      0.861538        0.573460   \n",
       "87  549.0      0.737648  0.959075      0.846923        0.568330   \n",
       "71  674.0      0.731502  1.110921      0.852308        0.551402   \n",
       "62  949.0      0.724276  1.306046      0.840769        0.545055   \n",
       "58  874.0      0.707514  1.094051      0.841538        0.509524   \n",
       "86  999.0      0.700652  1.356591      0.829231        0.504464   \n",
       "\n",
       "    val_f1_class_0  runtime_sec  total_epochs  trainable_params  \n",
       "83        0.930954  2440.230735          1000             88400  \n",
       "95        0.931660  1252.736297          1000             88400  \n",
       "77        0.930491  1323.405299          1000             88400  \n",
       "81        0.934911  3062.517461          1000             88400  \n",
       "79        0.924080   866.376918          1000             88400  \n",
       "78        0.925857  1011.316697          1000             88400  \n",
       "76        0.927683  1437.813789          1000             88400  \n",
       "96        0.923650  1033.490723          1000             88400  \n",
       "70        0.923505   942.991109          1000             88400  \n",
       "93        0.921860  1706.394955          1000             88400  \n",
       "84        0.921432  2007.406228          1000             88400  \n",
       "69        0.921650  1180.309417          1000             88400  \n",
       "67        0.924068  1423.331413          1000             88400  \n",
       "80        0.927273  4947.597631          1000             88400  \n",
       "74        0.918140  2169.700055          1000             88400  \n",
       "65        0.922090  2170.002377          1000             88400  \n",
       "90        0.917355  2666.657123          1000             88400  \n",
       "87        0.906966  4478.096315          1000             88400  \n",
       "71        0.911602  4415.639785          1000             88400  \n",
       "62        0.903497  4373.975848          1000             88400  \n",
       "58        0.905505  7947.329873          1000             88400  \n",
       "86        0.896840  1923.672788          1000             88400  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.part == \"part_2a\") & (df[\"tags\"].str.contains(\"lstm\"))].iloc[:,:12].sort_values(by=\"val_f1_macro\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d0f007e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_f1_macro</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1_class_1</th>\n",
       "      <th>val_f1_class_0</th>\n",
       "      <th>runtime_sec</th>\n",
       "      <th>total_epochs</th>\n",
       "      <th>trainable_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>o96gxicw</td>\n",
       "      <td>sleek-planet-180</td>\n",
       "      <td>decimate, gcn, part2a</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.673085</td>\n",
       "      <td>1.962007</td>\n",
       "      <td>0.805385</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.881053</td>\n",
       "      <td>2302.479808</td>\n",
       "      <td>1000</td>\n",
       "      <td>93600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>yzrzpebq</td>\n",
       "      <td>upbeat-tree-174</td>\n",
       "      <td>decimate, gcn, part2a</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0.668214</td>\n",
       "      <td>1.741350</td>\n",
       "      <td>0.813077</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.887448</td>\n",
       "      <td>5214.090533</td>\n",
       "      <td>1000</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>18q4ju3d</td>\n",
       "      <td>breezy-eon-191</td>\n",
       "      <td>gcn, part2a, window_downsample</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.662317</td>\n",
       "      <td>0.650667</td>\n",
       "      <td>0.818462</td>\n",
       "      <td>0.432692</td>\n",
       "      <td>0.891941</td>\n",
       "      <td>1899.028225</td>\n",
       "      <td>1000</td>\n",
       "      <td>48800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>49yw8t66</td>\n",
       "      <td>copper-lake-202</td>\n",
       "      <td>gcn, part2a, wavelet</td>\n",
       "      <td>624.0</td>\n",
       "      <td>0.660021</td>\n",
       "      <td>4.053404</td>\n",
       "      <td>0.808462</td>\n",
       "      <td>0.435374</td>\n",
       "      <td>0.884669</td>\n",
       "      <td>1914.018708</td>\n",
       "      <td>1000</td>\n",
       "      <td>41600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>hyebwt66</td>\n",
       "      <td>soft-deluge-183</td>\n",
       "      <td>decimate, gcn, part2a</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>0.648393</td>\n",
       "      <td>0.811538</td>\n",
       "      <td>0.431555</td>\n",
       "      <td>0.887045</td>\n",
       "      <td>1823.730414</td>\n",
       "      <td>1000</td>\n",
       "      <td>42400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>qfq2v8vd</td>\n",
       "      <td>different-yogurt-190</td>\n",
       "      <td>gcn, part2a, window_downsample</td>\n",
       "      <td>249.0</td>\n",
       "      <td>0.656485</td>\n",
       "      <td>2.490861</td>\n",
       "      <td>0.802308</td>\n",
       "      <td>0.432671</td>\n",
       "      <td>0.880298</td>\n",
       "      <td>1950.781189</td>\n",
       "      <td>1000</td>\n",
       "      <td>55200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>9l118qut</td>\n",
       "      <td>jumping-haze-177</td>\n",
       "      <td>decimate, gcn, part2a</td>\n",
       "      <td>699.0</td>\n",
       "      <td>0.655642</td>\n",
       "      <td>5.694632</td>\n",
       "      <td>0.813077</td>\n",
       "      <td>0.422803</td>\n",
       "      <td>0.888481</td>\n",
       "      <td>3462.054785</td>\n",
       "      <td>1000</td>\n",
       "      <td>208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>en1nbwtu</td>\n",
       "      <td>likely-pond-186</td>\n",
       "      <td>gcn, part2a, window_downsample</td>\n",
       "      <td>399.0</td>\n",
       "      <td>0.655428</td>\n",
       "      <td>3.677298</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.866412</td>\n",
       "      <td>3454.897880</td>\n",
       "      <td>1000</td>\n",
       "      <td>208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>ehfsng4j</td>\n",
       "      <td>magic-sky-199</td>\n",
       "      <td>gcn, part2a, wavelet</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.652516</td>\n",
       "      <td>0.884255</td>\n",
       "      <td>0.790769</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.871698</td>\n",
       "      <td>3578.393610</td>\n",
       "      <td>1000</td>\n",
       "      <td>209000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>py4olxej</td>\n",
       "      <td>robust-wind-189</td>\n",
       "      <td>gcn, part2a, window_downsample</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.651481</td>\n",
       "      <td>1.195303</td>\n",
       "      <td>0.771538</td>\n",
       "      <td>0.446927</td>\n",
       "      <td>0.856035</td>\n",
       "      <td>2324.710297</td>\n",
       "      <td>1000</td>\n",
       "      <td>93600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>tr5r6w9p</td>\n",
       "      <td>laced-tree-184</td>\n",
       "      <td>decimate, gcn, part2a</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.649832</td>\n",
       "      <td>0.855185</td>\n",
       "      <td>0.803077</td>\n",
       "      <td>0.418182</td>\n",
       "      <td>0.881481</td>\n",
       "      <td>1725.309137</td>\n",
       "      <td>1000</td>\n",
       "      <td>29600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>vcxisdty</td>\n",
       "      <td>glorious-frog-203</td>\n",
       "      <td>gcn, part2a, wavelet</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.647744</td>\n",
       "      <td>0.968749</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.410377</td>\n",
       "      <td>0.885110</td>\n",
       "      <td>1796.222720</td>\n",
       "      <td>1000</td>\n",
       "      <td>29600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>ipxl2wee</td>\n",
       "      <td>zesty-moon-200</td>\n",
       "      <td>gcn, part2a, wavelet</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.647439</td>\n",
       "      <td>1.750060</td>\n",
       "      <td>0.804615</td>\n",
       "      <td>0.412037</td>\n",
       "      <td>0.882841</td>\n",
       "      <td>2607.487793</td>\n",
       "      <td>1000</td>\n",
       "      <td>113000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>ilbfhvql</td>\n",
       "      <td>colorful-snowflake-192</td>\n",
       "      <td>gcn, part2a, window_downsample</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0.642488</td>\n",
       "      <td>1.565714</td>\n",
       "      <td>0.773846</td>\n",
       "      <td>0.425781</td>\n",
       "      <td>0.859195</td>\n",
       "      <td>1777.259729</td>\n",
       "      <td>1000</td>\n",
       "      <td>32100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>xcylci4l</td>\n",
       "      <td>whole-wave-181</td>\n",
       "      <td>decimate, gcn, part2a</td>\n",
       "      <td>449.0</td>\n",
       "      <td>0.635705</td>\n",
       "      <td>3.834781</td>\n",
       "      <td>0.783846</td>\n",
       "      <td>0.403397</td>\n",
       "      <td>0.868013</td>\n",
       "      <td>1939.536648</td>\n",
       "      <td>1000</td>\n",
       "      <td>55200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>yvf2w410</td>\n",
       "      <td>deep-surf-197</td>\n",
       "      <td>dct_downsample, gcn, part2a</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.629286</td>\n",
       "      <td>3.091702</td>\n",
       "      <td>0.790769</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.873957</td>\n",
       "      <td>3200.290008</td>\n",
       "      <td>1000</td>\n",
       "      <td>29600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>ho0xay04</td>\n",
       "      <td>iconic-fog-193</td>\n",
       "      <td>gcn, part2a, window_downsample</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.613184</td>\n",
       "      <td>0.809476</td>\n",
       "      <td>0.802308</td>\n",
       "      <td>0.342711</td>\n",
       "      <td>0.883658</td>\n",
       "      <td>1719.520406</td>\n",
       "      <td>1000</td>\n",
       "      <td>24400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0vncyo13</td>\n",
       "      <td>stoic-bee-201</td>\n",
       "      <td>gcn, part2a, wavelet</td>\n",
       "      <td>449.0</td>\n",
       "      <td>0.611648</td>\n",
       "      <td>4.997794</td>\n",
       "      <td>0.756154</td>\n",
       "      <td>0.374753</td>\n",
       "      <td>0.848543</td>\n",
       "      <td>2136.392399</td>\n",
       "      <td>1000</td>\n",
       "      <td>65500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>5qrlvjkf</td>\n",
       "      <td>clear-glade-196</td>\n",
       "      <td>dct_downsample, gcn, part2a</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.606612</td>\n",
       "      <td>1.184113</td>\n",
       "      <td>0.787692</td>\n",
       "      <td>0.339713</td>\n",
       "      <td>0.873511</td>\n",
       "      <td>3377.248481</td>\n",
       "      <td>1000</td>\n",
       "      <td>55200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>3q1sjc0o</td>\n",
       "      <td>honest-sponge-194</td>\n",
       "      <td>dct_downsample, gcn, part2a</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.598924</td>\n",
       "      <td>2.487822</td>\n",
       "      <td>0.733846</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.831548</td>\n",
       "      <td>4274.947155</td>\n",
       "      <td>1000</td>\n",
       "      <td>208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>utqdhhh0</td>\n",
       "      <td>helpful-cloud-198</td>\n",
       "      <td>dct_downsample, gcn, part2a</td>\n",
       "      <td>249.0</td>\n",
       "      <td>0.595940</td>\n",
       "      <td>1.577847</td>\n",
       "      <td>0.771538</td>\n",
       "      <td>0.329571</td>\n",
       "      <td>0.862309</td>\n",
       "      <td>3216.187184</td>\n",
       "      <td>1000</td>\n",
       "      <td>23200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>l7ij42ys</td>\n",
       "      <td>chocolate-plasma-195</td>\n",
       "      <td>dct_downsample, gcn, part2a</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.593409</td>\n",
       "      <td>4.817339</td>\n",
       "      <td>0.793077</td>\n",
       "      <td>0.308483</td>\n",
       "      <td>0.878336</td>\n",
       "      <td>3581.390606</td>\n",
       "      <td>1000</td>\n",
       "      <td>93600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       run_id                run_name                            tags  epoch  \\\n",
       "88   o96gxicw        sleek-planet-180           decimate, gcn, part2a  149.0   \n",
       "82   yzrzpebq         upbeat-tree-174           decimate, gcn, part2a  324.0   \n",
       "99   18q4ju3d          breezy-eon-191  gcn, part2a, window_downsample   74.0   \n",
       "110  49yw8t66         copper-lake-202            gcn, part2a, wavelet  624.0   \n",
       "91   hyebwt66         soft-deluge-183           decimate, gcn, part2a   74.0   \n",
       "98   qfq2v8vd    different-yogurt-190  gcn, part2a, window_downsample  249.0   \n",
       "85   9l118qut        jumping-haze-177           decimate, gcn, part2a  699.0   \n",
       "94   en1nbwtu         likely-pond-186  gcn, part2a, window_downsample  399.0   \n",
       "107  ehfsng4j           magic-sky-199            gcn, part2a, wavelet   99.0   \n",
       "97   py4olxej         robust-wind-189  gcn, part2a, window_downsample   99.0   \n",
       "92   tr5r6w9p          laced-tree-184           decimate, gcn, part2a  124.0   \n",
       "111  vcxisdty       glorious-frog-203            gcn, part2a, wavelet  149.0   \n",
       "108  ipxl2wee          zesty-moon-200            gcn, part2a, wavelet  174.0   \n",
       "100  ilbfhvql  colorful-snowflake-192  gcn, part2a, window_downsample  199.0   \n",
       "89   xcylci4l          whole-wave-181           decimate, gcn, part2a  449.0   \n",
       "105  yvf2w410           deep-surf-197     dct_downsample, gcn, part2a  274.0   \n",
       "101  ho0xay04          iconic-fog-193  gcn, part2a, window_downsample  174.0   \n",
       "109  0vncyo13           stoic-bee-201            gcn, part2a, wavelet  449.0   \n",
       "104  5qrlvjkf         clear-glade-196     dct_downsample, gcn, part2a   74.0   \n",
       "102  3q1sjc0o       honest-sponge-194     dct_downsample, gcn, part2a   99.0   \n",
       "106  utqdhhh0       helpful-cloud-198     dct_downsample, gcn, part2a  249.0   \n",
       "103  l7ij42ys    chocolate-plasma-195     dct_downsample, gcn, part2a  274.0   \n",
       "\n",
       "     val_f1_macro  val_loss  val_accuracy  val_f1_class_1  val_f1_class_0  \\\n",
       "88       0.673085  1.962007      0.805385        0.465116        0.881053   \n",
       "82       0.668214  1.741350      0.813077        0.448980        0.887448   \n",
       "99       0.662317  0.650667      0.818462        0.432692        0.891941   \n",
       "110      0.660021  4.053404      0.808462        0.435374        0.884669   \n",
       "91       0.659300  0.648393      0.811538        0.431555        0.887045   \n",
       "98       0.656485  2.490861      0.802308        0.432671        0.880298   \n",
       "85       0.655642  5.694632      0.813077        0.422803        0.888481   \n",
       "94       0.655428  3.677298      0.784615        0.444444        0.866412   \n",
       "107      0.652516  0.884255      0.790769        0.433333        0.871698   \n",
       "97       0.651481  1.195303      0.771538        0.446927        0.856035   \n",
       "92       0.649832  0.855185      0.803077        0.418182        0.881481   \n",
       "111      0.647744  0.968749      0.807692        0.410377        0.885110   \n",
       "108      0.647439  1.750060      0.804615        0.412037        0.882841   \n",
       "100      0.642488  1.565714      0.773846        0.425781        0.859195   \n",
       "89       0.635705  3.834781      0.783846        0.403397        0.868013   \n",
       "105      0.629286  3.091702      0.790769        0.384615        0.873957   \n",
       "101      0.613184  0.809476      0.802308        0.342711        0.883658   \n",
       "109      0.611648  4.997794      0.756154        0.374753        0.848543   \n",
       "104      0.606612  1.184113      0.787692        0.339713        0.873511   \n",
       "102      0.598924  2.487822      0.733846        0.366300        0.831548   \n",
       "106      0.595940  1.577847      0.771538        0.329571        0.862309   \n",
       "103      0.593409  4.817339      0.793077        0.308483        0.878336   \n",
       "\n",
       "     runtime_sec  total_epochs  trainable_params  \n",
       "88   2302.479808          1000             93600  \n",
       "82   5214.090533          1000            400000  \n",
       "99   1899.028225          1000             48800  \n",
       "110  1914.018708          1000             41600  \n",
       "91   1823.730414          1000             42400  \n",
       "98   1950.781189          1000             55200  \n",
       "85   3462.054785          1000            208000  \n",
       "94   3454.897880          1000            208000  \n",
       "107  3578.393610          1000            209000  \n",
       "97   2324.710297          1000             93600  \n",
       "92   1725.309137          1000             29600  \n",
       "111  1796.222720          1000             29600  \n",
       "108  2607.487793          1000            113000  \n",
       "100  1777.259729          1000             32100  \n",
       "89   1939.536648          1000             55200  \n",
       "105  3200.290008          1000             29600  \n",
       "101  1719.520406          1000             24400  \n",
       "109  2136.392399          1000             65500  \n",
       "104  3377.248481          1000             55200  \n",
       "102  4274.947155          1000            208000  \n",
       "106  3216.187184          1000             23200  \n",
       "103  3581.390606          1000             93600  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.part == \"part_2a\") & (df[\"tags\"].str.contains(\"gcn\"))].iloc[:,:12].sort_values(by=\"val_f1_macro\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecb385f",
   "metadata": {},
   "source": [
    "## Part 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2474822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_f1_macro</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1_class_1</th>\n",
       "      <th>val_f1_class_0</th>\n",
       "      <th>runtime_sec</th>\n",
       "      <th>total_epochs</th>\n",
       "      <th>trainable_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>xe33zh99</td>\n",
       "      <td>northern-durian-248</td>\n",
       "      <td>cnn1d_medium, kaggle, lstm, part2b</td>\n",
       "      <td>449.0</td>\n",
       "      <td>0.870581</td>\n",
       "      <td>0.345199</td>\n",
       "      <td>0.924615</td>\n",
       "      <td>0.786957</td>\n",
       "      <td>0.954206</td>\n",
       "      <td>3794.414399</td>\n",
       "      <td>1000</td>\n",
       "      <td>145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>3lg8jawa</td>\n",
       "      <td>fluent-spaceship-252</td>\n",
       "      <td>cnn1d_large, lstm, part2b</td>\n",
       "      <td>724.0</td>\n",
       "      <td>0.860526</td>\n",
       "      <td>0.482502</td>\n",
       "      <td>0.916154</td>\n",
       "      <td>0.772443</td>\n",
       "      <td>0.948609</td>\n",
       "      <td>3881.166162</td>\n",
       "      <td>1000</td>\n",
       "      <td>188000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2yg9l5qs</td>\n",
       "      <td>winter-aardvark-238</td>\n",
       "      <td>cnn1d_small, lstm, part2b</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.841447</td>\n",
       "      <td>0.478782</td>\n",
       "      <td>0.909231</td>\n",
       "      <td>0.737778</td>\n",
       "      <td>0.945116</td>\n",
       "      <td>3755.898387</td>\n",
       "      <td>1000</td>\n",
       "      <td>124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>hkaxkasi</td>\n",
       "      <td>misty-microwave-231</td>\n",
       "      <td>lstm, non_over_lap, part2b, patch_tst</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.801727</td>\n",
       "      <td>0.422459</td>\n",
       "      <td>0.887692</td>\n",
       "      <td>0.671171</td>\n",
       "      <td>0.932282</td>\n",
       "      <td>15595.191129</td>\n",
       "      <td>250</td>\n",
       "      <td>239000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>9ctlopl1</td>\n",
       "      <td>electric-silence-272</td>\n",
       "      <td>lstm, over_lap, part2b, patch_tst</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.795830</td>\n",
       "      <td>0.324695</td>\n",
       "      <td>0.887692</td>\n",
       "      <td>0.658879</td>\n",
       "      <td>0.932781</td>\n",
       "      <td>15475.687148</td>\n",
       "      <td>250</td>\n",
       "      <td>239000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       run_id              run_name                                   tags  \\\n",
       "123  xe33zh99   northern-durian-248     cnn1d_medium, kaggle, lstm, part2b   \n",
       "124  3lg8jawa  fluent-spaceship-252              cnn1d_large, lstm, part2b   \n",
       "121  2yg9l5qs   winter-aardvark-238              cnn1d_small, lstm, part2b   \n",
       "119  hkaxkasi   misty-microwave-231  lstm, non_over_lap, part2b, patch_tst   \n",
       "126  9ctlopl1  electric-silence-272      lstm, over_lap, part2b, patch_tst   \n",
       "\n",
       "     epoch  val_f1_macro  val_loss  val_accuracy  val_f1_class_1  \\\n",
       "123  449.0      0.870581  0.345199      0.924615        0.786957   \n",
       "124  724.0      0.860526  0.482502      0.916154        0.772443   \n",
       "121  674.0      0.841447  0.478782      0.909231        0.737778   \n",
       "119  124.0      0.801727  0.422459      0.887692        0.671171   \n",
       "126   49.0      0.795830  0.324695      0.887692        0.658879   \n",
       "\n",
       "     val_f1_class_0   runtime_sec  total_epochs  trainable_params  \n",
       "123        0.954206   3794.414399          1000            145000  \n",
       "124        0.948609   3881.166162          1000            188000  \n",
       "121        0.945116   3755.898387          1000            124000  \n",
       "119        0.932282  15595.191129           250            239000  \n",
       "126        0.932781  15475.687148           250            239000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.part == \"part_2b\") & (df[\"tags\"].str.contains(\"lstm\"))].iloc[:,:12].sort_values(by=\"val_f1_macro\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73e74c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_f1_macro</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1_class_1</th>\n",
       "      <th>val_f1_class_0</th>\n",
       "      <th>runtime_sec</th>\n",
       "      <th>total_epochs</th>\n",
       "      <th>trainable_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>4jvl7gra</td>\n",
       "      <td>twilight-leaf-281</td>\n",
       "      <td>cnn1d_large, gcn, part2b</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.810259</td>\n",
       "      <td>0.405038</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.677003</td>\n",
       "      <td>0.943516</td>\n",
       "      <td>4250.769686</td>\n",
       "      <td>1000</td>\n",
       "      <td>155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>n3o1qled</td>\n",
       "      <td>zesty-shape-325</td>\n",
       "      <td>cnn1d_large, gcn, kaggle, part2b</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.805992</td>\n",
       "      <td>0.347378</td>\n",
       "      <td>0.896923</td>\n",
       "      <td>0.673171</td>\n",
       "      <td>0.938813</td>\n",
       "      <td>4212.047623</td>\n",
       "      <td>1000</td>\n",
       "      <td>155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>5uv5z81u</td>\n",
       "      <td>eager-hill-280</td>\n",
       "      <td>cnn1d_medium, gcn, part2b</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.800159</td>\n",
       "      <td>0.296992</td>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.661654</td>\n",
       "      <td>0.938664</td>\n",
       "      <td>4202.100068</td>\n",
       "      <td>1000</td>\n",
       "      <td>112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>az516un9</td>\n",
       "      <td>fine-glade-278</td>\n",
       "      <td>cnn1d_small, gcn, part2b</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.797713</td>\n",
       "      <td>0.299791</td>\n",
       "      <td>0.880769</td>\n",
       "      <td>0.668094</td>\n",
       "      <td>0.927332</td>\n",
       "      <td>4179.266001</td>\n",
       "      <td>1000</td>\n",
       "      <td>91300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>obexylo6</td>\n",
       "      <td>clean-jazz-244</td>\n",
       "      <td>gcn, non_over_lap, part2b, patch_tst</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.660996</td>\n",
       "      <td>0.487126</td>\n",
       "      <td>0.818462</td>\n",
       "      <td>0.429952</td>\n",
       "      <td>0.892040</td>\n",
       "      <td>15600.503123</td>\n",
       "      <td>250</td>\n",
       "      <td>206000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>hn0eexuq</td>\n",
       "      <td>zany-water-279</td>\n",
       "      <td>gcn, over_lap, part2b, patch_tst</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.660021</td>\n",
       "      <td>3.931639</td>\n",
       "      <td>0.808462</td>\n",
       "      <td>0.435374</td>\n",
       "      <td>0.884669</td>\n",
       "      <td>15445.699140</td>\n",
       "      <td>250</td>\n",
       "      <td>206000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       run_id           run_name                                  tags  epoch  \\\n",
       "130  4jvl7gra  twilight-leaf-281              cnn1d_large, gcn, part2b   74.0   \n",
       "157  n3o1qled    zesty-shape-325      cnn1d_large, gcn, kaggle, part2b   74.0   \n",
       "129  5uv5z81u     eager-hill-280             cnn1d_medium, gcn, part2b   49.0   \n",
       "127  az516un9     fine-glade-278              cnn1d_small, gcn, part2b   49.0   \n",
       "122  obexylo6     clean-jazz-244  gcn, non_over_lap, part2b, patch_tst   24.0   \n",
       "128  hn0eexuq     zany-water-279      gcn, over_lap, part2b, patch_tst   74.0   \n",
       "\n",
       "     val_f1_macro  val_loss  val_accuracy  val_f1_class_1  val_f1_class_0  \\\n",
       "130      0.810259  0.405038      0.903846        0.677003        0.943516   \n",
       "157      0.805992  0.347378      0.896923        0.673171        0.938813   \n",
       "129      0.800159  0.296992      0.896154        0.661654        0.938664   \n",
       "127      0.797713  0.299791      0.880769        0.668094        0.927332   \n",
       "122      0.660996  0.487126      0.818462        0.429952        0.892040   \n",
       "128      0.660021  3.931639      0.808462        0.435374        0.884669   \n",
       "\n",
       "      runtime_sec  total_epochs  trainable_params  \n",
       "130   4250.769686          1000            155000  \n",
       "157   4212.047623          1000            155000  \n",
       "129   4202.100068          1000            112000  \n",
       "127   4179.266001          1000             91300  \n",
       "122  15600.503123           250            206000  \n",
       "128  15445.699140           250            206000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.part == \"part_2b\") & (df[\"tags\"].str.contains(\"gcn\"))].iloc[:,:12].sort_values(by=\"val_f1_macro\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85afc0e8",
   "metadata": {},
   "source": [
    "## Part 2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b73606d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_f1_macro</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1_class_1</th>\n",
       "      <th>val_f1_class_0</th>\n",
       "      <th>runtime_sec</th>\n",
       "      <th>total_epochs</th>\n",
       "      <th>trainable_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>jq32zp6r</td>\n",
       "      <td>dulcet-lion-299</td>\n",
       "      <td>lstm, part2c, small_overlap, table_2c, window_gcn</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.808523</td>\n",
       "      <td>0.402236</td>\n",
       "      <td>0.889231</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.932836</td>\n",
       "      <td>10110.163708</td>\n",
       "      <td>250</td>\n",
       "      <td>148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>lgiwxp18</td>\n",
       "      <td>solar-firefly-296</td>\n",
       "      <td>kaggle, lstm, part2c, part2d, table_2c, weight...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.805219</td>\n",
       "      <td>0.304460</td>\n",
       "      <td>0.896923</td>\n",
       "      <td>0.671569</td>\n",
       "      <td>0.938869</td>\n",
       "      <td>3358.505183</td>\n",
       "      <td>50</td>\n",
       "      <td>148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6qfnvqyf</td>\n",
       "      <td>super-sun-303</td>\n",
       "      <td>large_window, lstm, part2c, table_2c, window_gcn</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.800725</td>\n",
       "      <td>0.598685</td>\n",
       "      <td>0.886923</td>\n",
       "      <td>0.669663</td>\n",
       "      <td>0.931787</td>\n",
       "      <td>8229.069116</td>\n",
       "      <td>250</td>\n",
       "      <td>164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6eczkgp7</td>\n",
       "      <td>misunderstood-donkey-298</td>\n",
       "      <td>lstm, no_overlap, part2c, table_2c, window_gcn</td>\n",
       "      <td>235.0</td>\n",
       "      <td>0.800020</td>\n",
       "      <td>0.533650</td>\n",
       "      <td>0.881538</td>\n",
       "      <td>0.672340</td>\n",
       "      <td>0.927700</td>\n",
       "      <td>8520.879743</td>\n",
       "      <td>250</td>\n",
       "      <td>148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>pxbwzcz3</td>\n",
       "      <td>pleasant-cloud-297</td>\n",
       "      <td>kaggle, lstm, part2c, weighted_sampler, window...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.791536</td>\n",
       "      <td>0.315073</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.658120</td>\n",
       "      <td>0.924953</td>\n",
       "      <td>3375.339607</td>\n",
       "      <td>50</td>\n",
       "      <td>148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0r3q73zj</td>\n",
       "      <td>kind-spaceship-304</td>\n",
       "      <td>large_window, lstm, part2c, small_overlap, tab...</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.788672</td>\n",
       "      <td>0.460802</td>\n",
       "      <td>0.879231</td>\n",
       "      <td>0.650334</td>\n",
       "      <td>0.927011</td>\n",
       "      <td>5316.964903</td>\n",
       "      <td>250</td>\n",
       "      <td>164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>vzzz3np6</td>\n",
       "      <td>usual-durian-294</td>\n",
       "      <td>baseline, lstm, part2c, window_gcn</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.785011</td>\n",
       "      <td>0.311763</td>\n",
       "      <td>0.883077</td>\n",
       "      <td>0.639810</td>\n",
       "      <td>0.930211</td>\n",
       "      <td>3353.910635</td>\n",
       "      <td>50</td>\n",
       "      <td>148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>xe3i8n7s</td>\n",
       "      <td>restful-star-305</td>\n",
       "      <td>large_window, lstm, no_overlap, part2c, table_...</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.774562</td>\n",
       "      <td>0.410758</td>\n",
       "      <td>0.868462</td>\n",
       "      <td>0.629067</td>\n",
       "      <td>0.920056</td>\n",
       "      <td>4622.703426</td>\n",
       "      <td>250</td>\n",
       "      <td>164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>299k563a</td>\n",
       "      <td>wild-vortex-295</td>\n",
       "      <td>lr, lstm, part2c, window_gcn</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.743688</td>\n",
       "      <td>0.354738</td>\n",
       "      <td>0.857692</td>\n",
       "      <td>0.572748</td>\n",
       "      <td>0.914629</td>\n",
       "      <td>3367.280622</td>\n",
       "      <td>50</td>\n",
       "      <td>148000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       run_id                  run_name  \\\n",
       "140  jq32zp6r           dulcet-lion-299   \n",
       "137  lgiwxp18         solar-firefly-296   \n",
       "141  6qfnvqyf             super-sun-303   \n",
       "139  6eczkgp7  misunderstood-donkey-298   \n",
       "138  pxbwzcz3        pleasant-cloud-297   \n",
       "142  0r3q73zj        kind-spaceship-304   \n",
       "135  vzzz3np6          usual-durian-294   \n",
       "143  xe3i8n7s          restful-star-305   \n",
       "136  299k563a           wild-vortex-295   \n",
       "\n",
       "                                                  tags  epoch  val_f1_macro  \\\n",
       "140  lstm, part2c, small_overlap, table_2c, window_gcn  147.0      0.808523   \n",
       "137  kaggle, lstm, part2c, part2d, table_2c, weight...   49.0      0.805219   \n",
       "141   large_window, lstm, part2c, table_2c, window_gcn  197.0      0.800725   \n",
       "139     lstm, no_overlap, part2c, table_2c, window_gcn  235.0      0.800020   \n",
       "138  kaggle, lstm, part2c, weighted_sampler, window...   39.0      0.791536   \n",
       "142  large_window, lstm, part2c, small_overlap, tab...  107.0      0.788672   \n",
       "135                 baseline, lstm, part2c, window_gcn   41.0      0.785011   \n",
       "143  large_window, lstm, no_overlap, part2c, table_...   83.0      0.774562   \n",
       "136                       lr, lstm, part2c, window_gcn   45.0      0.743688   \n",
       "\n",
       "     val_loss  val_accuracy  val_f1_class_1  val_f1_class_0   runtime_sec  \\\n",
       "140  0.402236      0.889231        0.684211        0.932836  10110.163708   \n",
       "137  0.304460      0.896923        0.671569        0.938869   3358.505183   \n",
       "141  0.598685      0.886923        0.669663        0.931787   8229.069116   \n",
       "139  0.533650      0.881538        0.672340        0.927700   8520.879743   \n",
       "138  0.315073      0.876923        0.658120        0.924953   3375.339607   \n",
       "142  0.460802      0.879231        0.650334        0.927011   5316.964903   \n",
       "135  0.311763      0.883077        0.639810        0.930211   3353.910635   \n",
       "143  0.410758      0.868462        0.629067        0.920056   4622.703426   \n",
       "136  0.354738      0.857692        0.572748        0.914629   3367.280622   \n",
       "\n",
       "     total_epochs  trainable_params  \n",
       "140           250            148000  \n",
       "137            50            148000  \n",
       "141           250            164000  \n",
       "139           250            148000  \n",
       "138            50            148000  \n",
       "142           250            164000  \n",
       "135            50            148000  \n",
       "143           250            164000  \n",
       "136            50            148000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.part == \"part_2c\") & (df[\"tags\"].str.contains(\"gcn\"))].iloc[:,:12].sort_values(by=\"val_f1_macro\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa5f3af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(36.36363636363637)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df[\"total_epochs\"] == 50)][\"epoch\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "368bd73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(289636.36363636365)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df[\"total_epochs\"] == 50)][\"trainable_params\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f598a01",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e95e7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>epoch</th>\n",
       "      <th>val_f1_macro</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1_class_1</th>\n",
       "      <th>val_f1_class_0</th>\n",
       "      <th>runtime_sec</th>\n",
       "      <th>total_epochs</th>\n",
       "      <th>trainable_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>fv9amftf</td>\n",
       "      <td>gentle-violet-326</td>\n",
       "      <td>kaggle, learned_pool, lstm_att, part2d, part3a...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.847316</td>\n",
       "      <td>0.414346</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.745370</td>\n",
       "      <td>0.949262</td>\n",
       "      <td>3079.260911</td>\n",
       "      <td>50</td>\n",
       "      <td>464000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>x5m36lad</td>\n",
       "      <td>chocolate-lake-320</td>\n",
       "      <td>correlation_adj, learned_pool, lstm_att, part3...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.812544</td>\n",
       "      <td>0.458881</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.690265</td>\n",
       "      <td>0.934823</td>\n",
       "      <td>16194.809829</td>\n",
       "      <td>50</td>\n",
       "      <td>464000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>azhji2zo</td>\n",
       "      <td>fresh-blaze-396</td>\n",
       "      <td>dist_1_5, fold_1, lstm_att learned_pool, part3...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.792925</td>\n",
       "      <td>0.314149</td>\n",
       "      <td>0.881090</td>\n",
       "      <td>0.657807</td>\n",
       "      <td>0.928042</td>\n",
       "      <td>3465.799217</td>\n",
       "      <td>50</td>\n",
       "      <td>153000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>4u9d3h1e</td>\n",
       "      <td>peach-snowball-321</td>\n",
       "      <td>learned_adj, learned_pool, lstm_att, part3a, w...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.449153</td>\n",
       "      <td>0.478395</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>4638.535955</td>\n",
       "      <td>50</td>\n",
       "      <td>464000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       run_id            run_name  \\\n",
       "158  fv9amftf   gentle-violet-326   \n",
       "152  x5m36lad  chocolate-lake-320   \n",
       "213  azhji2zo     fresh-blaze-396   \n",
       "153  4u9d3h1e  peach-snowball-321   \n",
       "\n",
       "                                                  tags  epoch  val_f1_macro  \\\n",
       "158  kaggle, learned_pool, lstm_att, part2d, part3a...   47.0      0.847316   \n",
       "152  correlation_adj, learned_pool, lstm_att, part3...   39.0      0.812544   \n",
       "213  dist_1_5, fold_1, lstm_att learned_pool, part3...   45.0      0.792925   \n",
       "153  learned_adj, learned_pool, lstm_att, part3a, w...    1.0      0.449153   \n",
       "\n",
       "     val_loss  val_accuracy  val_f1_class_1  val_f1_class_0   runtime_sec  \\\n",
       "158  0.414346      0.915385        0.745370        0.949262   3079.260911   \n",
       "152  0.458881      0.892308        0.690265        0.934823  16194.809829   \n",
       "213  0.314149      0.881090        0.657807        0.928042   3465.799217   \n",
       "153  0.478395      0.815385        0.000000        0.898305   4638.535955   \n",
       "\n",
       "     total_epochs  trainable_params  \n",
       "158            50            464000  \n",
       "152            50            464000  \n",
       "213            50            153000  \n",
       "153            50            464000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.part == \"part_3\") & (df[\"tags\"].str.contains(\"gcn\"))].iloc[:,:12].sort_values(by=\"val_f1_macro\",ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
